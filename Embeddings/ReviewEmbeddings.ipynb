{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_pickle('Pickle/reviews.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = reviews.sample(500000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maddy\\anaconda3\\envs\\goodreads\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Initialize your model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "def save_embeddings_incrementally(reviews_df, model, interval=100):\n",
    "    embeddings_file = 'Pickle/review_embeddings.pkl'\n",
    "    \n",
    "    # Load existing embeddings if they exist\n",
    "    if os.path.exists(embeddings_file):\n",
    "        embeddings_df = pd.read_pickle(embeddings_file)\n",
    "    else:\n",
    "        embeddings_df = pd.DataFrame(columns=['index', 'review_id', 'embeddings'])\n",
    "    \n",
    "    # Ensure combined_features are non-null\n",
    "    reviews_df = reviews_df.dropna(subset=['review_text']).reset_index(drop=True)\n",
    "\n",
    "    new_embeddings = []\n",
    "\n",
    "    for i in tqdm(range(len(reviews_df)), desc=\"Generating embeddings\"):\n",
    "        if i in embeddings_df['index'].values:\n",
    "            continue  # Skip if already processed\n",
    "        \n",
    "        embedding = model.encode(reviews_df.at[i, 'review_text'])\n",
    "        new_row = {'index': i, 'review_id': reviews_df.at[i, 'review_id'], 'embeddings': embedding}\n",
    "        new_embeddings.append(new_row)\n",
    "        \n",
    "        # Save periodically\n",
    "        if len(new_embeddings) % interval == 0:\n",
    "            new_embeddings_df = pd.DataFrame(new_embeddings)\n",
    "            embeddings_df = pd.concat([embeddings_df, new_embeddings_df], ignore_index=True)\n",
    "            embeddings_df.to_pickle(embeddings_file)\n",
    "            new_embeddings = []  # Reset the list\n",
    "    \n",
    "    # Save any remaining new embeddings\n",
    "    if new_embeddings:\n",
    "        new_embeddings_df = pd.DataFrame(new_embeddings)\n",
    "        embeddings_df = pd.concat([embeddings_df, new_embeddings_df], ignore_index=True)\n",
    "        embeddings_df.to_pickle(embeddings_file)\n",
    "\n",
    "    print(f\"Embeddings saved to {embeddings_file} successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings: 100%|██████████| 500000/500000 [7:02:16<00:00, 19.73it/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings saved to Pickle/review_embeddings.pkl successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Save embeddings incrementally\n",
    "save_embeddings_incrementally(reviews, model, interval=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_df = pd.read_pickle('Pickle/review_embeddings.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_df.set_index('review_id', inplace=True)\n",
    "\n",
    "def get_embedding(review_id):\n",
    "    try:\n",
    "        return embeddings_df.at[review_id, 'embeddings']\n",
    "    except KeyError:\n",
    "        return None\n",
    "\n",
    "reviews['embeddings'] = reviews['review_id'].progress_apply(get_embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reviews.to_pickle('Pickle/reviews.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "goodreads",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
