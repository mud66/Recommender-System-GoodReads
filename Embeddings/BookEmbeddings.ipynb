{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maddy\\anaconda3\\envs\\goodreads\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# Load the pickled chunks and concatenate them\n",
    "books_list = []\n",
    "\n",
    "with open('../Pickle/books.pkl', 'rb') as file:\n",
    "    while True:\n",
    "        try:\n",
    "            chunk = pickle.load(file)\n",
    "            books_list.append(chunk)\n",
    "        except EOFError:\n",
    "            break  # Stop when end of file is reached\n",
    "\n",
    "# Combine chunks into a single DataFrame\n",
    "books = pd.concat(books_list, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language_code</th>\n",
       "      <th>description</th>\n",
       "      <th>authors</th>\n",
       "      <th>book_id</th>\n",
       "      <th>title</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>title_without_series</th>\n",
       "      <th>filtered_genres</th>\n",
       "      <th>expanded_shelves</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eng</td>\n",
       "      <td>The war against Voldemort is not going well: e...</td>\n",
       "      <td>[J.K. Rowling, Mary GrandPre]</td>\n",
       "      <td>1</td>\n",
       "      <td>Harry Potter and the Half-Blood Prince (Harry ...</td>\n",
       "      <td>4.54</td>\n",
       "      <td>Harry Potter and the Half-Blood Prince (Harry ...</td>\n",
       "      <td>fantasy, paranormal, young-adult, fiction, chi...</td>\n",
       "      <td>fantasy fantasy fantasy fantasy fantasy fantas...</td>\n",
       "      <td>[-0.07355614, -0.0043452834, 0.07326843, 0.010...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>en-US</td>\n",
       "      <td>Bill Bryson's first travel book, The Lost Cont...</td>\n",
       "      <td>[Bill Bryson]</td>\n",
       "      <td>27</td>\n",
       "      <td>Neither Here nor There: Travels in Europe</td>\n",
       "      <td>3.88</td>\n",
       "      <td>Neither Here nor There: Travels in Europe</td>\n",
       "      <td>non-fiction, history, historical fiction, biog...</td>\n",
       "      <td>travel travel travel travel travel travel trav...</td>\n",
       "      <td>[0.075617716, 0.049203802, -0.08219313, 0.0366...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eng</td>\n",
       "      <td>Gerald Samper, an effete English snob, has his...</td>\n",
       "      <td>[James Hamilton-Paterson]</td>\n",
       "      <td>40</td>\n",
       "      <td>Cooking with Fernet Branca (Gerald Samper, #1)</td>\n",
       "      <td>3.61</td>\n",
       "      <td>Cooking with Fernet Branca (Gerald Samper, #1)</td>\n",
       "      <td>fiction</td>\n",
       "      <td>fiction fiction fiction fiction fiction fictio...</td>\n",
       "      <td>[0.012406698, -0.08666229, -0.041537926, 0.068...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eng</td>\n",
       "      <td>Rails is a full-stack, open source web framewo...</td>\n",
       "      <td>[Dave Thomas, David Heinemeier Hansson, Leon B...</td>\n",
       "      <td>45</td>\n",
       "      <td>Agile Web Development with Rails: A Pragmatic ...</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Agile Web Development with Rails: A Pragmatic ...</td>\n",
       "      <td>non-fiction</td>\n",
       "      <td>rails rails rails rails rails rails rails rail...</td>\n",
       "      <td>[0.014417239, -0.079731256, -0.09433866, 0.043...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>Wharton's final novel (completed by Marion Mai...</td>\n",
       "      <td>[Edith Wharton, Marion Mainwaring]</td>\n",
       "      <td>48</td>\n",
       "      <td>The Bucaneers</td>\n",
       "      <td>3.89</td>\n",
       "      <td>The Bucaneers</td>\n",
       "      <td>fiction, history, historical fiction, biograph...</td>\n",
       "      <td>classics classics classics classics classics c...</td>\n",
       "      <td>[0.0069107036, -0.1147475, -0.013718575, 0.003...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language_code                                        description  \\\n",
       "0           eng  The war against Voldemort is not going well: e...   \n",
       "1         en-US  Bill Bryson's first travel book, The Lost Cont...   \n",
       "2           eng  Gerald Samper, an effete English snob, has his...   \n",
       "3           eng  Rails is a full-stack, open source web framewo...   \n",
       "4                Wharton's final novel (completed by Marion Mai...   \n",
       "\n",
       "                                             authors  book_id  \\\n",
       "0                      [J.K. Rowling, Mary GrandPre]        1   \n",
       "1                                      [Bill Bryson]       27   \n",
       "2                          [James Hamilton-Paterson]       40   \n",
       "3  [Dave Thomas, David Heinemeier Hansson, Leon B...       45   \n",
       "4                 [Edith Wharton, Marion Mainwaring]       48   \n",
       "\n",
       "                                               title average_rating  \\\n",
       "0  Harry Potter and the Half-Blood Prince (Harry ...           4.54   \n",
       "1          Neither Here nor There: Travels in Europe           3.88   \n",
       "2     Cooking with Fernet Branca (Gerald Samper, #1)           3.61   \n",
       "3  Agile Web Development with Rails: A Pragmatic ...            3.9   \n",
       "4                                      The Bucaneers           3.89   \n",
       "\n",
       "                                title_without_series  \\\n",
       "0  Harry Potter and the Half-Blood Prince (Harry ...   \n",
       "1          Neither Here nor There: Travels in Europe   \n",
       "2     Cooking with Fernet Branca (Gerald Samper, #1)   \n",
       "3  Agile Web Development with Rails: A Pragmatic ...   \n",
       "4                                      The Bucaneers   \n",
       "\n",
       "                                     filtered_genres  \\\n",
       "0  fantasy, paranormal, young-adult, fiction, chi...   \n",
       "1  non-fiction, history, historical fiction, biog...   \n",
       "2                                            fiction   \n",
       "3                                        non-fiction   \n",
       "4  fiction, history, historical fiction, biograph...   \n",
       "\n",
       "                                    expanded_shelves  \\\n",
       "0  fantasy fantasy fantasy fantasy fantasy fantas...   \n",
       "1  travel travel travel travel travel travel trav...   \n",
       "2  fiction fiction fiction fiction fiction fictio...   \n",
       "3  rails rails rails rails rails rails rails rail...   \n",
       "4  classics classics classics classics classics c...   \n",
       "\n",
       "                                          embeddings  \n",
       "0  [-0.07355614, -0.0043452834, 0.07326843, 0.010...  \n",
       "1  [0.075617716, 0.049203802, -0.08219313, 0.0366...  \n",
       "2  [0.012406698, -0.08666229, -0.041537926, 0.068...  \n",
       "3  [0.014417239, -0.079731256, -0.09433866, 0.043...  \n",
       "4  [0.0069107036, -0.1147475, -0.013718575, 0.003...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books = books[books['filtered_genres'].apply(lambda x: bool(x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include_language_codes = ['', ' ', 'eng', 'en-US', 'en-GB', '--', 'en-CA', 'en-IN']\n",
    "books = books[books['language_code'].isin(include_language_codes)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from lingua import Language, LanguageDetectorBuilder\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# Initialize tqdm for Pandas apply\n",
    "tqdm.pandas()\n",
    "\n",
    "# Initialize the language detector\n",
    "detector = LanguageDetectorBuilder.from_all_languages().build()\n",
    "\n",
    "# Function to detect language\n",
    "def detect_language(text):\n",
    "    if not text or pd.isna(text):  # Handle empty or NaN values\n",
    "        return False\n",
    "    text = text[:250]  # Limit text length for faster processing\n",
    "\n",
    "    try:\n",
    "        detected_lang = detector.detect_language_of(text)\n",
    "        return detected_lang == Language.ENGLISH  # Direct Enum comparison\n",
    "    except Exception:\n",
    "        return False  # Assume non-English in case of an error\n",
    "\n",
    "# Define chunk size and output file\n",
    "chunk_size = 5000\n",
    "save_every = 10  # Save to pickle every 10 chunks\n",
    "output_pickle = \"../Pickle/books_filtered.pkl\"\n",
    "\n",
    "# Load existing processed books if the file exists\n",
    "if os.path.exists(output_pickle):\n",
    "    books_filtered = pd.read_pickle(output_pickle)\n",
    "    processed_books = set(books_filtered[\"book_id\"])  # Keep track of already processed book IDs\n",
    "else:\n",
    "    books_filtered = pd.DataFrame()  # Empty DataFrame to start with\n",
    "    processed_books = set()  # No books processed yet\n",
    "\n",
    "# Process only unprocessed books\n",
    "books_to_process = books[~books[\"book_id\"].isin(processed_books)]\n",
    "\n",
    "if books_to_process.empty:\n",
    "    print(\"All books are already processed. No new data to process.\")\n",
    "else:\n",
    "    print(f\"Processing {len(books_to_process)} new books...\")\n",
    "\n",
    "    buffer = []\n",
    "    for i, start in enumerate(tqdm(range(0, len(books_to_process), chunk_size), desc=\"Processing in chunks\")):\n",
    "        end = min(start + chunk_size, len(books_to_process))\n",
    "        books_chunk = books_to_process.iloc[start:end].copy()  # Ensure it's a proper DataFrame\n",
    "\n",
    "        # Apply language detection\n",
    "        books_chunk[\"is_english\"] = books_chunk[\"description\"].progress_apply(detect_language)\n",
    "\n",
    "        # Filter for English descriptions\n",
    "        books_chunk = books_chunk[books_chunk[\"is_english\"]].drop(columns=[\"is_english\"])\n",
    "\n",
    "        # Add to buffer\n",
    "        buffer.append(books_chunk)\n",
    "\n",
    "        # Every `save_every` chunks, concatenate and save\n",
    "        if (i + 1) % save_every == 0 or (i + 1) == len(range(0, len(books_to_process), chunk_size)): \n",
    "            buffer_df = pd.concat(buffer, ignore_index=True)\n",
    "            books_filtered = pd.concat([books_filtered, buffer_df], ignore_index=True)\n",
    "            books_filtered.to_pickle(output_pickle)  # Save to pickle\n",
    "            buffer = []  # Clear buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_books = pd.read_pickle(\"../Pickle/books_filtered.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "books = eng_books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books['combined_features'] = books.apply(\n",
    "    lambda row: f\"{row['title']} by {row['authors']}, \" +\n",
    "                f\"Description: {row['description']}, \" +\n",
    "                f\"Shelves: {row['expanded_shelves']}\" +\n",
    "                f\"Genres: {row['filtered_genres']}\",\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books = books.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Initialize your model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "def save_embeddings_incrementally(books_df, model, interval=100):\n",
    "    embeddings_file = '../Pickle/embeddings.pkl'\n",
    "    \n",
    "    # Load existing embeddings if they exist\n",
    "    if os.path.exists(embeddings_file):\n",
    "        embeddings_df = pd.read_pickle(embeddings_file)\n",
    "    else:\n",
    "        embeddings_df = pd.DataFrame(columns=['book_id', 'embeddings'])\n",
    "    \n",
    "    # Ensure combined_features are non-null\n",
    "    books_df = books_df.dropna(subset=['combined_features']).reset_index(drop=True)\n",
    "\n",
    "    new_embeddings = []\n",
    "\n",
    "    for i in tqdm(range(len(books_df)), desc=\"Generating embeddings\"):\n",
    "        book_id = books_df.at[i, 'book_id']\n",
    "        \n",
    "        # Skip if the book_id is already processed\n",
    "        if book_id in embeddings_df['book_id'].values:\n",
    "            continue\n",
    "        \n",
    "        # Generate embedding\n",
    "        embedding = model.encode(books_df.at[i, 'combined_features'])\n",
    "        \n",
    "        # Prepare new row\n",
    "        new_row = {'book_id': book_id, 'embeddings': embedding}\n",
    "        new_embeddings.append(new_row)\n",
    "        \n",
    "        # Save periodically\n",
    "        if len(new_embeddings) % interval == 0:\n",
    "            new_embeddings_df = pd.DataFrame(new_embeddings)\n",
    "            embeddings_df = pd.concat([embeddings_df, new_embeddings_df], ignore_index=True)\n",
    "            embeddings_df.to_pickle(embeddings_file)\n",
    "            new_embeddings = []  # Reset the list\n",
    "    \n",
    "    # Save any remaining new embeddings\n",
    "    if new_embeddings:\n",
    "        new_embeddings_df = pd.DataFrame(new_embeddings)\n",
    "        embeddings_df = pd.concat([embeddings_df, new_embeddings_df], ignore_index=True)\n",
    "        embeddings_df.to_pickle(embeddings_file)\n",
    "\n",
    "    print(f\"Embeddings saved to {embeddings_file} successfully!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_embeddings_incrementally(books, model, interval=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_df = pd.read_pickle('../Pickle/embeddings.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_df=embeddings_df.drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 577082/577082 [00:02<00:00, 210510.98it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "embeddings_df.set_index('book_id', inplace=True)\n",
    "\n",
    "def get_embedding(book_id):\n",
    "    try:\n",
    "        return embeddings_df.at[book_id, 'embeddings']\n",
    "    except KeyError:\n",
    "        return None\n",
    "\n",
    "books['embeddings'] = books['book_id'].progress_apply(get_embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 577082/577082 [03:29<00:00, 2760.12it/s] \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Ensure the progress_apply method from tqdm is used\n",
    "tqdm.pandas()\n",
    "\n",
    "# Split the DataFrame into chunks and save each chunk to a pickle file with a progress bar\n",
    "chunk_size = 10000  # Adjust the chunk size as needed\n",
    "num_chunks = len(books) // chunk_size + 1\n",
    "\n",
    "# Initialize the progress bar for rows\n",
    "progress_bar = tqdm(total=len(books))\n",
    "\n",
    "# Open the pickle file once before the loop\n",
    "with open('../Pickle/books.pkl', 'wb') as file:\n",
    "    for i in range(num_chunks):\n",
    "        start_idx = i * chunk_size\n",
    "        end_idx = (i + 1) * chunk_size\n",
    "        chunk = books.iloc[start_idx:end_idx]\n",
    "        \n",
    "        # Update progress bar for each row\n",
    "        for _, row in chunk.iterrows():\n",
    "            progress_bar.update(1)\n",
    "        \n",
    "        # Append each chunk to the pickle file\n",
    "        if i == 0:\n",
    "            # For the first chunk, use \"wb\" (write binary) mode\n",
    "            pickle.dump(chunk, file)\n",
    "        else:\n",
    "            # For subsequent chunks, use \"ab\" (append binary) mode\n",
    "            pickle.dump(chunk, file)\n",
    "\n",
    "# Close the progress bar\n",
    "progress_bar.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "goodreads",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
