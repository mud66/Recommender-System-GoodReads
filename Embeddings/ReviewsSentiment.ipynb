{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_pickle('../Pickle/reviews.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer and model\n",
    "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, model_max_length=512)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    words = word_tokenize(text)\n",
    "    filtered_words = [word for word in words if word.isalnum() and word.lower() not in stop_words]\n",
    "    cleaned_text = ' '.join(filtered_words)\n",
    "    \n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_text(text): \n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=512) \n",
    "    truncated_text = tokenizer.decode(inputs['input_ids'][0], skip_special_tokens=True) \n",
    "    return truncated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews['cleaned_text'] = reviews['review_text'].progress_apply(preprocess_text)\n",
    "reviews['truncated_text'] = reviews['cleaned_text'].progress_apply(truncate_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = reviews.dropna(subset=['truncated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Initialize your sentiment analysis model\n",
    "def save_sentiment_incrementally(reviews_df, sentiment_pipeline, interval=300):\n",
    "    sentiment_file = '../Pickle/review_score.pkl'\n",
    "    \n",
    "    # Load existing sentiment data if it exists\n",
    "    if os.path.exists(sentiment_file):\n",
    "        reviews_with_sentiment = pd.read_pickle(sentiment_file)\n",
    "    else:\n",
    "        reviews_with_sentiment = pd.DataFrame(columns=['review_id', 'sentiment', 'confidence'])\n",
    "    \n",
    "    # Ensure that reviews are non-null and reset index\n",
    "    reviews_df = reviews_df.dropna(subset=['truncated_text']).reset_index(drop=True)\n",
    "\n",
    "    # Get processed review IDs\n",
    "    processed_review_ids = set(reviews_with_sentiment['review_id'].values)\n",
    "    \n",
    "    new_sentiments = []\n",
    "\n",
    "    for i in tqdm(range(len(reviews_df)), desc=\"Processing reviews for sentiment\"):\n",
    "        review_id = reviews_df.at[i, 'review_id']\n",
    "        \n",
    "        # Skip if the review_id is already processed\n",
    "        if review_id in processed_review_ids:\n",
    "            continue\n",
    "        \n",
    "        # Get the review text and perform sentiment analysis\n",
    "        review_text = reviews_df.at[i, 'truncated_text']\n",
    "        sentiment_result = sentiment_pipeline(review_text)[0]\n",
    "        sentiment = sentiment_result['label']\n",
    "        confidence = sentiment_result['score']\n",
    "        \n",
    "        # Append new sentiment result\n",
    "        new_sentiments.append({'review_id': review_id, 'sentiment': sentiment, 'confidence': confidence})\n",
    "        \n",
    "        # Mark this review_id as processed\n",
    "        processed_review_ids.add(review_id)\n",
    "        \n",
    "        # Save periodically after every 'interval' reviews\n",
    "        if len(new_sentiments) % interval == 0:\n",
    "            new_sentiments_df = pd.DataFrame(new_sentiments)\n",
    "            reviews_with_sentiment = pd.concat([reviews_with_sentiment, new_sentiments_df], ignore_index=True)\n",
    "            reviews_with_sentiment.to_pickle(sentiment_file)\n",
    "            new_sentiments = []  # Reset the list\n",
    "            print(f\"Processed and saved batch {i + 1}/{len(reviews_df)}.\")\n",
    "\n",
    "    # Save any remaining sentiments after the loop\n",
    "    if new_sentiments:\n",
    "        new_sentiments_df = pd.DataFrame(new_sentiments)\n",
    "        reviews_with_sentiment = pd.concat([reviews_with_sentiment, new_sentiments_df], ignore_index=True)\n",
    "        reviews_with_sentiment.to_pickle(sentiment_file)\n",
    "\n",
    "    print(f\"Sentiment analysis results saved to {sentiment_file} successfully!\")\n",
    "\n",
    "# Example usage\n",
    "save_sentiment_incrementally(reviews, sentiment_pipeline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_sentiment = pd.read_pickle('../Pickle/review_score.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_sentiment['confidence_score'] = [\n",
    "    1 - row['confidence'] if row['sentiment'] == 0 else row ['confidence']\n",
    "    for _,row in review_sentiment.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>confidence</th>\n",
       "      <th>confidence_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5cd416f3efc3f944fce4ce2db2290d5e</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.979499</td>\n",
       "      <td>0.979499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dfdbb7b0eb5a7e4c26d59a937e2e5feb</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.719051</td>\n",
       "      <td>0.719051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5e212a62bced17b4dbe41150e5bb9037</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.991836</td>\n",
       "      <td>0.991836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fdd13cad0695656be99828cd75d6eb73</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.996752</td>\n",
       "      <td>0.996752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bd0df91c9d918c0e433b9ab3a9a5c451</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.999605</td>\n",
       "      <td>0.999605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000995</th>\n",
       "      <td>fca575edd179f0d349a0949bb4a2dc42</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.900867</td>\n",
       "      <td>0.900867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000996</th>\n",
       "      <td>4803d91f0555983fc4db7c8b44b3eba8</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.811458</td>\n",
       "      <td>0.811458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000997</th>\n",
       "      <td>cc25c79c14b0b94509b0eee08164fe73</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.999701</td>\n",
       "      <td>0.999701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000998</th>\n",
       "      <td>2422ddc0e9e39c6eb72f9af566c27baa</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.999779</td>\n",
       "      <td>0.999779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000999</th>\n",
       "      <td>622c72eace1ef56aae77ef6ee362e85f</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.998554</td>\n",
       "      <td>0.998554</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1001000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                review_id sentiment  confidence  \\\n",
       "0        5cd416f3efc3f944fce4ce2db2290d5e  POSITIVE    0.979499   \n",
       "1        dfdbb7b0eb5a7e4c26d59a937e2e5feb  POSITIVE    0.719051   \n",
       "2        5e212a62bced17b4dbe41150e5bb9037  POSITIVE    0.991836   \n",
       "3        fdd13cad0695656be99828cd75d6eb73  POSITIVE    0.996752   \n",
       "4        bd0df91c9d918c0e433b9ab3a9a5c451  POSITIVE    0.999605   \n",
       "...                                   ...       ...         ...   \n",
       "1000995  fca575edd179f0d349a0949bb4a2dc42  NEGATIVE    0.900867   \n",
       "1000996  4803d91f0555983fc4db7c8b44b3eba8  NEGATIVE    0.811458   \n",
       "1000997  cc25c79c14b0b94509b0eee08164fe73  POSITIVE    0.999701   \n",
       "1000998  2422ddc0e9e39c6eb72f9af566c27baa  POSITIVE    0.999779   \n",
       "1000999  622c72eace1ef56aae77ef6ee362e85f  POSITIVE    0.998554   \n",
       "\n",
       "         confidence_score  \n",
       "0                0.979499  \n",
       "1                0.719051  \n",
       "2                0.991836  \n",
       "3                0.996752  \n",
       "4                0.999605  \n",
       "...                   ...  \n",
       "1000995          0.900867  \n",
       "1000996          0.811458  \n",
       "1000997          0.999701  \n",
       "1000998          0.999779  \n",
       "1000999          0.998554  \n",
       "\n",
       "[1001000 rows x 4 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_sentiment.to_pickle('../Pickle/review_score.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "goodreads",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
