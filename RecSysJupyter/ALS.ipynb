{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threadpoolctl\n",
    "threadpoolctl.threadpool_limits(1, \"blas\")\n",
    "from surprise import accuracy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from implicit import als"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read = pd.read_pickle('../Pickle/read.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read = read[read['is_read']== 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read = read.drop(columns=[\"rating\", \"is_reviewed\"], errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read = read.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_data_with_single_interactions(read):\n",
    "    # Identify users and books that appear only once in the dataset\n",
    "    user_counts = read['user_id'].value_counts()\n",
    "    book_counts = read['book_id'].value_counts()\n",
    "\n",
    "    # Find interactions where user or book appears only once\n",
    "    single_interactions = read[\n",
    "        read['user_id'].isin(user_counts[user_counts == 1].index) | \n",
    "        read['book_id'].isin(book_counts[book_counts == 1].index)\n",
    "    ]\n",
    "\n",
    "    # Remove those interactions from the main dataset\n",
    "    remaining_interactions = read[~read.index.isin(single_interactions.index)]\n",
    "\n",
    "    # Split the remaining interactions into train and test using sklearn's train_test_split\n",
    "    train_df, test_df = train_test_split(remaining_interactions, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Add the single interactions to the training set\n",
    "    train_df = pd.concat([train_df, single_interactions], ignore_index=True)\n",
    "\n",
    "\n",
    "    return train_df, test_df\n",
    "\n",
    "train_df, test_df = split_data_with_single_interactions(read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Assign categorical indices to users and books\n",
    "user_cat = pd.Categorical(read[\"user_id\"])\n",
    "book_cat = pd.Categorical(read[\"book_id\"])\n",
    "\n",
    "read[\"user_idx\"] = user_cat.codes\n",
    "read[\"book_idx\"] = book_cat.codes\n",
    "\n",
    "train_df[\"user_idx\"] = pd.Categorical(train_df[\"user_id\"], categories=user_cat.categories).codes\n",
    "train_df[\"book_idx\"] = pd.Categorical(train_df[\"book_id\"], categories=book_cat.categories).codes\n",
    "\n",
    "test_df[\"user_idx\"] = pd.Categorical(test_df[\"user_id\"], categories=user_cat.categories).codes\n",
    "test_df[\"book_idx\"] = pd.Categorical(test_df[\"book_id\"], categories=book_cat.categories).codes\n",
    "\n",
    "# Step 3: Combine all unique book IDs from both train and test datasets\n",
    "all_book_ids = pd.concat([train_df['book_id'], test_df['book_id']]).unique()\n",
    "\n",
    "# Step 4: Create a mapping from book IDs to unique indices\n",
    "book_id_to_index = {book_id: idx for idx, book_id in enumerate(all_book_ids)}\n",
    "\n",
    "# Step 5: Map book IDs to indices in both train and test datasets\n",
    "train_df['book_idx'] = train_df['book_id'].map(book_id_to_index)\n",
    "test_df['book_idx'] = test_df['book_id'].map(book_id_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Create the train and test matrices (binary data: 1 for read, 0 for not read)\n",
    "train_matrix = csr_matrix((train_df[\"is_read\"], (train_df[\"user_idx\"], train_df[\"book_idx\"])))\n",
    "test_matrix = csr_matrix((test_df[\"is_read\"], (test_df[\"user_idx\"], test_df[\"book_idx\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping for user_id and book_id to indices\n",
    "user_mapping = {user_id: idx for idx, user_id in enumerate(read['user_id'].unique())}\n",
    "book_mapping = {book_id: idx for idx, book_id in enumerate(read['book_id'].unique())}\n",
    "\n",
    "# Map the original user_id and book_id to their respective indices\n",
    "read['user_idx'] = read['user_id'].map(user_mapping)\n",
    "read['book_idx'] = read['book_id'].map(book_mapping)\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Create the sparse CSR matrix directly\n",
    "interaction_matrix_sparse_csr = csr_matrix(\n",
    "    (read['is_read'], (read['user_idx'], read['book_idx'])),\n",
    "    shape=(len(user_mapping), len(book_mapping))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check number of rows in the sparse matrix\n",
    "num_rows = interaction_matrix_sparse_csr.shape[0]\n",
    "num_unique_users = len(user_mapping)\n",
    "\n",
    "print(f\"Number of rows in the sparse matrix: {num_rows}\")\n",
    "print(f\"Number of unique users: {num_unique_users}\")\n",
    "\n",
    "# Check if each user has exactly one row in the matrix (user_idx should be unique)\n",
    "unique_user_indices = read['user_idx'].nunique()\n",
    "print(f\"Number of unique user indices: {unique_user_indices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read[['user_id', 'user_idx']].drop_duplicates().sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read[['book_id', 'book_idx']].drop_duplicates().sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the ALS model\n",
    "model = als.AlternatingLeastSquares(\n",
    "    factors=100,  # Number of latent factors\n",
    "    regularization=0.1,  # Regularization strength\n",
    "    iterations=100 , # Number of iterations\n",
    "    alpha = 40\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "model.fit(train_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "model.user_factors = normalize(model.user_factors)\n",
    "model.item_factors = normalize(model.item_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the row corresponding to the user\n",
    "user_row = interaction_matrix_sparse_csr[1904]\n",
    "\n",
    "# Use the model to recommend items based on this single user's interaction row\n",
    "recommendations = model.recommend(1904, user_row, N=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get recommended book IDs and confidence scores\n",
    "recommended_books, scores = recommendations  \n",
    "\n",
    "# Print results\n",
    "for book, score in zip(recommended_books, scores):\n",
    "    print(f\"Book ID: {book}, Confidence Score: {score:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_idx = 46803  # Replace with the item ID (book) you want to explain\n",
    "\n",
    "# Call explain method to get explanations for the recommendation\n",
    "explanation = model.explain(1904, interaction_matrix_sparse_csr, item_idx, N=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract item IDs and weights from the explanation\n",
    "explanation_items = explanation[1]  # This is the list of (item_id, weight) tuples\n",
    "\n",
    "# Iterate through the explanation and print item IDs and weights\n",
    "print(f\"Explanation for item {item_idx} recommended to user {1904}:\")\n",
    "for item, weight in explanation_items:\n",
    "    print(f\"Item {item} with weight {weight}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score\n",
    "\n",
    "def fast_evaluate(model, test_matrix, top_k, sample_size):\n",
    "    user_factors = model.user_factors\n",
    "    item_factors = model.item_factors\n",
    "\n",
    "    num_users = test_matrix.shape[0]\n",
    "    faiss.normalize_L2(user_factors)\n",
    "    # Normalize item factors for cosine similarity (only if not already normalised)\n",
    "    faiss.normalize_L2(item_factors)\n",
    "\n",
    "    # Sample users for fast evaluation\n",
    "    sampled_users = np.random.choice(num_users, size=int(num_users * sample_size), replace=False)\n",
    "\n",
    "    # Use FAISS for fast top-K retrieval\n",
    "    index = faiss.IndexFlatIP(item_factors.shape[1])  # Inner product index\n",
    "    index.add(item_factors)  # Add item embeddings\n",
    "    scores, top_k_items = index.search(user_factors[sampled_users], k=top_k)  # Get top-K per user\n",
    "\n",
    "    all_predictions = []\n",
    "    all_true_labels = []\n",
    "\n",
    "    # Process sampled users\n",
    "    for user in tqdm(sampled_users, desc=\"Evaluating users\", total=len(sampled_users), dynamic_ncols=True, leave=True):\n",
    "        true_items = set(test_matrix[user].nonzero()[0])  # Items user interacted with\n",
    "        pred_items = top_k_items[sampled_users.tolist().index(user)]  # Top-K predicted items\n",
    "\n",
    "        true_labels = [1 if item in true_items else 0 for item in pred_items]\n",
    "        all_predictions.extend(scores[sampled_users.tolist().index(user)])  # Use actual FAISS scores\n",
    "        all_true_labels.extend(true_labels)\n",
    "\n",
    "    # Compute metrics\n",
    "    precision_at_k = sum(all_true_labels) / (len(sampled_users) * top_k)\n",
    "    recall_at_k = sum(all_true_labels) / test_matrix[sampled_users].nnz\n",
    "    auc_score = roc_auc_score(all_true_labels, all_predictions)\n",
    "\n",
    "    print(f'Precision@{top_k}: {precision_at_k:.4f}')\n",
    "    print(f'Recall@{top_k}: {recall_at_k:.4f}')\n",
    "    print(f'AUC: {auc_score:.4f}')\n",
    "\n",
    "    return precision_at_k, recall_at_k, auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_at_k, recall_at_k, auc_score = fast_evaluate(model, test_matrix, top_k=5, sample_size=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "goodreads",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
