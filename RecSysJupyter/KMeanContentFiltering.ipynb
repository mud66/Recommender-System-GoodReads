{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from umap import UMAP\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "sns.set_theme(style=\"white\", palette=\"muted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "books = pd.read_pickle('../Pickle/books.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.vstack(books['embeddings'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices, test_indices = train_test_split(np.arange(embedding_matrix.shape[0]), test_size=0.2, random_state=42)\n",
    "train_embeddings, test_embeddings = embedding_matrix[train_indices], embedding_matrix[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler() \n",
    "scaled_train_embeddings = scaler.fit_transform(train_embeddings)\n",
    "scaled_test_embeddings = scaler.transform(test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=50, random_state=42)\n",
    "pca_train_embeddings = pca.fit_transform(scaled_train_embeddings)\n",
    "pca_test_embeddings = pca.transform(scaled_test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_model = UMAP(n_components=3, random_state=42) \n",
    "umap_train_embeddings = umap_model.fit_transform(pca_train_embeddings)\n",
    "umap_test_embeddings = umap_model.transform(pca_test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embeddings = np.vstack((umap_train_embeddings, umap_test_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "iso_forest = IsolationForest(contamination=0.05, random_state=42) \n",
    "outliers = iso_forest.fit_predict(umap_train_embeddings) \n",
    "clean_train_embeddings = umap_train_embeddings[outliers == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import KernelPCA\n",
    "def apply_kernel_pca_in_batches(embeddings, n_components=45, kernel='rbf', batch_size=10000):\n",
    "    n_samples = embeddings.shape[0]\n",
    "    transformed_embeddings = np.zeros((n_samples, n_components))\n",
    "    kpca = KernelPCA(n_components=n_components, kernel=kernel, random_state=42)\n",
    "    \n",
    "    for i in tqdm(range(0, n_samples, batch_size), desc=\"Processing Batches\"):\n",
    "        end_idx = min(i + batch_size, n_samples)\n",
    "        batch = embeddings[i:end_idx]\n",
    "        transformed_batch = kpca.fit_transform(batch)\n",
    "        transformed_embeddings[i:end_idx] = transformed_batch\n",
    "    \n",
    "    return transformed_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpca_train_embeddings = apply_kernel_pca_in_batches(clean_train_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpca_train_embeddings_unclean = apply_kernel_pca_in_batches(umap_train_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpca_test_embeddings = apply_kernel_pca_in_batches(umap_test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 11\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_train_clusters = kmeans.fit_predict(kpca_train_embeddings)\n",
    "train_clusters = np.full(len(kpca_train_embeddings_unclean), -1)\n",
    "train_clusters[outliers == 1] = clean_train_clusters\n",
    "test_clusters = kmeans.predict(kpca_test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add clusters to books data\n",
    "train_books = books.iloc[train_indices].copy()\n",
    "train_books['cluster'] = train_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_books = books.iloc[test_indices].copy()\n",
    "test_books['cluster'] = test_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_books = pd.concat([train_books, test_books])\n",
    "combined_kpca_embeddings = np.vstack((kpca_train_embeddings_unclean, kpca_test_embeddings))\n",
    "combined_kpca_embeddings_3d = combined_kpca_embeddings[:, :3]\n",
    "combined_clusters = np.concatenate((train_clusters, test_clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations_by_cluster(book_id, books_df, embeddings, top_n=5):\n",
    "    if book_id not in books_df['book_id'].values:\n",
    "        print(f\"Book ID {book_id} not found in the books DataFrame.\")\n",
    "        return pd.DataFrame(columns=['title', 'authors', 'book_id'])\n",
    "    \n",
    "    book_cluster = books_df.loc[books_df['book_id'] == book_id, 'cluster'].values[0]\n",
    "    cluster_books = books_df[books_df['cluster'] == book_cluster]\n",
    "    \n",
    "    if len(cluster_books) <= top_n:\n",
    "        return cluster_books[['title', 'authors', 'book_id']]\n",
    "    \n",
    "    book_id_to_index = {id_: idx for idx, id_ in enumerate(books_df['book_id'].values)}\n",
    "    book_idx = book_id_to_index[book_id]\n",
    "    \n",
    "    cluster_book_indices = [book_id_to_index[id_] for id_ in cluster_books['book_id'].values]\n",
    "    cluster_embedding_matrix = embeddings[cluster_book_indices]\n",
    "    \n",
    "    sim_scores = cosine_similarity(embeddings[book_idx].reshape(1, -1), cluster_embedding_matrix).flatten()\n",
    "    cluster_book_ids = cluster_books['book_id'].values\n",
    "    sim_scores_dict = {cluster_book_ids[i]: sim_scores[i] for i in range(len(cluster_book_ids)) if cluster_book_ids[i] != book_id}\n",
    "    \n",
    "    sorted_book_ids = sorted(sim_scores_dict, key=sim_scores_dict.get, reverse=True)\n",
    "    top_book_ids = sorted_book_ids[:top_n]\n",
    "    top_books = cluster_books[cluster_books['book_id'].isin(top_book_ids)]\n",
    "    \n",
    "    return top_books[['title', 'authors', 'book_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_books.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_recommendations_by_cluster(10445325, all_books, combined_kpca_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_recommendations_by_cluster(2838499, all_books, combined_kpca_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_recommendations_by_cluster(959076, all_books, combined_kpca_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elbow method for optimal number of clusters\n",
    "k_values = range(1, 15)\n",
    "inertia_values = []\n",
    "\n",
    "for k in k_values:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(kpca_test_embeddings)\n",
    "    inertia_values.append(kmeans.inertia_)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(k_values, inertia_values, 'bo-', markersize=8)\n",
    "plt.xlabel('Number of clusters (k)')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('Elbow Method for Optimal Number of Clusters')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Evaluation\n",
    "silhouette_avg_test = silhouette_score(kpca_test_embeddings, test_clusters)\n",
    "print(f'Silhouette Score (Test): {silhouette_avg_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intra_cluster_distance(embeddings, clusters, centroids):\n",
    "    total_distance = 0\n",
    "    for i, label in enumerate(clusters):\n",
    "        if label != -1 and label < len(centroids):\n",
    "            cluster_center = centroids[label]\n",
    "            distance = np.linalg.norm(embeddings[i] - cluster_center)\n",
    "            total_distance += distance \n",
    "    return total_distance / np.sum(clusters != -1)\n",
    "\n",
    "\n",
    "print(intra_cluster_distance(kpca_test_embeddings, test_clusters, kmeans.cluster_centers_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = pd.DataFrame(combined_kpca_embeddings_3d, columns=['Component 1', 'Component 2', 'Component 3'])\n",
    "plot_df['cluster'] = combined_clusters\n",
    "\n",
    "# 3D Plotting\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "scatter = ax.scatter(plot_df['Component 1'], plot_df['Component 2'], plot_df['Component 3'], \n",
    "                     c=plot_df['cluster'], cmap='tab10', s=50, alpha=0.6, edgecolor='w')\n",
    "\n",
    "ax.set_xlabel('Component 1')\n",
    "ax.set_ylabel('Component 2')\n",
    "ax.set_zlabel('Component 3')\n",
    "plt.title('3D Clustering of Books')\n",
    "\n",
    "legend1 = ax.legend(*scatter.legend_elements(), title=\"Cluster\")\n",
    "ax.add_artist(legend1)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "goodreads",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
