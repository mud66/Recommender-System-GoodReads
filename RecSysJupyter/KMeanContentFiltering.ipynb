{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from umap import UMAP\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "sns.set_theme(style=\"white\", palette=\"muted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "books = pd.read_pickle('../Pickle/books.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.vstack(books['embeddings'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices, test_indices = train_test_split(np.arange(embedding_matrix.shape[0]), test_size=0.2, random_state=42)\n",
    "train_embeddings, test_embeddings = embedding_matrix[train_indices], embedding_matrix[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler() \n",
    "scaled_train_embeddings = scaler.fit_transform(train_embeddings)\n",
    "scaled_test_embeddings = scaler.transform(test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=50, random_state=42)\n",
    "pca_train_embeddings = pca.fit_transform(scaled_train_embeddings)\n",
    "pca_test_embeddings = pca.transform(scaled_test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maddy\\anaconda3\\envs\\goodreads\\Lib\\site-packages\\umap\\umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "umap_model = UMAP(n_components=3, random_state=42) \n",
    "umap_train_embeddings = umap_model.fit_transform(pca_train_embeddings)\n",
    "umap_test_embeddings = umap_model.transform(pca_test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embeddings = np.vstack((umap_train_embeddings, umap_test_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "iso_forest = IsolationForest(contamination=0.05, random_state=42) \n",
    "outliers = iso_forest.fit_predict(umap_train_embeddings) \n",
    "clean_train_embeddings = umap_train_embeddings[outliers == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import KernelPCA\n",
    "def apply_kernel_pca_in_batches(embeddings, n_components=45, kernel='rbf', batch_size=10000):\n",
    "    n_samples = embeddings.shape[0]\n",
    "    transformed_embeddings = np.zeros((n_samples, n_components))\n",
    "    kpca = KernelPCA(n_components=n_components, kernel=kernel, random_state=42)\n",
    "    \n",
    "    for i in tqdm(range(0, n_samples, batch_size), desc=\"Processing Batches\"):\n",
    "        end_idx = min(i + batch_size, n_samples)\n",
    "        batch = embeddings[i:end_idx]\n",
    "        transformed_batch = kpca.fit_transform(batch)\n",
    "        transformed_embeddings[i:end_idx] = transformed_batch\n",
    "    \n",
    "    return transformed_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  64%|██████▍   | 18/28 [15:34<08:39, 51.93s/it]\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 9.77 MiB for an array with shape (2560000,) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m kpca_train_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mapply_kernel_pca_in_batches\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclean_train_embeddings\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[10], line 10\u001b[0m, in \u001b[0;36mapply_kernel_pca_in_batches\u001b[1;34m(embeddings, n_components, kernel, batch_size)\u001b[0m\n\u001b[0;32m      8\u001b[0m     end_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(i \u001b[38;5;241m+\u001b[39m batch_size, n_samples)\n\u001b[0;32m      9\u001b[0m     batch \u001b[38;5;241m=\u001b[39m embeddings[i:end_idx]\n\u001b[1;32m---> 10\u001b[0m     transformed_batch \u001b[38;5;241m=\u001b[39m \u001b[43mkpca\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     transformed_embeddings[i:end_idx] \u001b[38;5;241m=\u001b[39m transformed_batch\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m transformed_embeddings\n",
      "File \u001b[1;32mc:\\Users\\maddy\\anaconda3\\envs\\goodreads\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:313\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 313\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    314\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    315\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    316\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    317\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    318\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    319\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\maddy\\anaconda3\\envs\\goodreads\\Lib\\site-packages\\sklearn\\decomposition\\_kernel_pca.py:474\u001b[0m, in \u001b[0;36mKernelPCA.fit_transform\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams):\n\u001b[0;32m    454\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model from data in X and transform X.\u001b[39;00m\n\u001b[0;32m    455\u001b[0m \n\u001b[0;32m    456\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    472\u001b[0m \u001b[38;5;124;03m        Returns the instance itself.\u001b[39;00m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 474\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    476\u001b[0m     \u001b[38;5;66;03m# no need to use the kernel to transform X, use shortcut expression\u001b[39;00m\n\u001b[0;32m    477\u001b[0m     X_transformed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meigenvectors_ \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meigenvalues_)\n",
      "File \u001b[1;32mc:\\Users\\maddy\\anaconda3\\envs\\goodreads\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\maddy\\anaconda3\\envs\\goodreads\\Lib\\site-packages\\sklearn\\decomposition\\_kernel_pca.py:442\u001b[0m, in \u001b[0;36mKernelPCA.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    440\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_centerer \u001b[38;5;241m=\u001b[39m KernelCenterer()\u001b[38;5;241m.\u001b[39mset_output(transform\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    441\u001b[0m K \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_kernel(X)\n\u001b[1;32m--> 442\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    444\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_inverse_transform:\n\u001b[0;32m    445\u001b[0m     \u001b[38;5;66;03m# no need to use the kernel to transform X, use shortcut expression\u001b[39;00m\n\u001b[0;32m    446\u001b[0m     X_transformed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meigenvectors_ \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meigenvalues_)\n",
      "File \u001b[1;32mc:\\Users\\maddy\\anaconda3\\envs\\goodreads\\Lib\\site-packages\\sklearn\\decomposition\\_kernel_pca.py:350\u001b[0m, in \u001b[0;36mKernelPCA._fit_transform\u001b[1;34m(self, K)\u001b[0m\n\u001b[0;32m    346\u001b[0m     eigen_solver \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meigen_solver\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m eigen_solver \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdense\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;66;03m# Note: subset_by_index specifies the indices of smallest/largest to return\u001b[39;00m\n\u001b[1;32m--> 350\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meigenvalues_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meigenvectors_ \u001b[38;5;241m=\u001b[39m \u001b[43meigh\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m        \u001b[49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubset_by_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mK\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_components\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m eigen_solver \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marpack\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    354\u001b[0m     v0 \u001b[38;5;241m=\u001b[39m _init_arpack_v0(K\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state)\n",
      "File \u001b[1;32mc:\\Users\\maddy\\anaconda3\\envs\\goodreads\\Lib\\site-packages\\scipy\\_lib\\deprecation.py:213\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    211\u001b[0m extra_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(all_args)\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extra_args \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 213\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;66;03m# extra_args > 0\u001b[39;00m\n\u001b[0;32m    216\u001b[0m args_msg \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(kwonly_args[:extra_args], args[\u001b[38;5;241m-\u001b[39mextra_args:])\n\u001b[0;32m    219\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\maddy\\anaconda3\\envs\\goodreads\\Lib\\site-packages\\scipy\\linalg\\_decomp.py:560\u001b[0m, in \u001b[0;36meigh\u001b[1;34m(a, b, lower, eigvals_only, overwrite_a, overwrite_b, turbo, eigvals, type, check_finite, subset_by_index, subset_by_value, driver)\u001b[0m\n\u001b[0;32m    557\u001b[0m         lwork_args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlwork\u001b[39m\u001b[38;5;124m'\u001b[39m: lw}\n\u001b[0;32m    559\u001b[0m     drv_args\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlower\u001b[39m\u001b[38;5;124m'\u001b[39m: lower, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcompute_v\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _job \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mN\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m})\n\u001b[1;32m--> 560\u001b[0m     w, v, \u001b[38;5;241m*\u001b[39mother_args, info \u001b[38;5;241m=\u001b[39m \u001b[43mdrv\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ma1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdrv_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlwork_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    562\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Generalized problem\u001b[39;00m\n\u001b[0;32m    563\u001b[0m     \u001b[38;5;66;03m# 'gvd' doesn't have lwork query\u001b[39;00m\n\u001b[0;32m    564\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m driver \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgvd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 9.77 MiB for an array with shape (2560000,) and data type float32"
     ]
    }
   ],
   "source": [
    "kpca_train_embeddings = apply_kernel_pca_in_batches(clean_train_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpca_train_embeddings_unclean = apply_kernel_pca_in_batches(umap_train_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpca_test_embeddings = apply_kernel_pca_in_batches(umap_test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 11\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_train_clusters = kmeans.fit_predict(kpca_train_embeddings)\n",
    "train_clusters = np.full(len(kpca_train_embeddings_unclean), -1)\n",
    "train_clusters[outliers == 1] = clean_train_clusters\n",
    "test_clusters = kmeans.predict(kpca_test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add clusters to books data\n",
    "train_books = books.iloc[train_indices].copy()\n",
    "train_books['cluster'] = train_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_books = books.iloc[test_indices].copy()\n",
    "test_books['cluster'] = test_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_books = pd.concat([train_books, test_books])\n",
    "combined_kpca_embeddings = np.vstack((kpca_train_embeddings_unclean, kpca_test_embeddings))\n",
    "combined_kpca_embeddings_3d = combined_kpca_embeddings[:, :3]\n",
    "combined_clusters = np.concatenate((train_clusters, test_clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations_by_cluster(book_id, books_df, embeddings, top_n=5):\n",
    "    if book_id not in books_df['book_id'].values:\n",
    "        print(f\"Book ID {book_id} not found in the books DataFrame.\")\n",
    "        return pd.DataFrame(columns=['title', 'authors', 'book_id'])\n",
    "    \n",
    "    book_cluster = books_df.loc[books_df['book_id'] == book_id, 'cluster'].values[0]\n",
    "    cluster_books = books_df[books_df['cluster'] == book_cluster]\n",
    "    \n",
    "    if len(cluster_books) <= top_n:\n",
    "        return cluster_books[['title', 'authors', 'book_id']]\n",
    "    \n",
    "    book_id_to_index = {id_: idx for idx, id_ in enumerate(books_df['book_id'].values)}\n",
    "    book_idx = book_id_to_index[book_id]\n",
    "    \n",
    "    cluster_book_indices = [book_id_to_index[id_] for id_ in cluster_books['book_id'].values]\n",
    "    cluster_embedding_matrix = embeddings[cluster_book_indices]\n",
    "    \n",
    "    sim_scores = cosine_similarity(embeddings[book_idx].reshape(1, -1), cluster_embedding_matrix).flatten()\n",
    "    cluster_book_ids = cluster_books['book_id'].values\n",
    "    sim_scores_dict = {cluster_book_ids[i]: sim_scores[i] for i in range(len(cluster_book_ids)) if cluster_book_ids[i] != book_id}\n",
    "    \n",
    "    sorted_book_ids = sorted(sim_scores_dict, key=sim_scores_dict.get, reverse=True)\n",
    "    top_book_ids = sorted_book_ids[:top_n]\n",
    "    top_books = cluster_books[cluster_books['book_id'].isin(top_book_ids)]\n",
    "    \n",
    "    return top_books[['title', 'authors', 'book_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_books.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_recommendations_by_cluster(10445325, all_books, combined_kpca_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_recommendations_by_cluster(2838499, all_books, combined_kpca_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_recommendations_by_cluster(959076, all_books, combined_kpca_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elbow method for optimal number of clusters\n",
    "k_values = range(1, 15)\n",
    "inertia_values = []\n",
    "\n",
    "for k in k_values:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(kpca_test_embeddings)\n",
    "    inertia_values.append(kmeans.inertia_)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(k_values, inertia_values, 'bo-', markersize=8)\n",
    "plt.xlabel('Number of clusters (k)')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('Elbow Method for Optimal Number of Clusters')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Evaluation\n",
    "silhouette_avg_test = silhouette_score(kpca_test_embeddings, test_clusters)\n",
    "print(f'Silhouette Score (Test): {silhouette_avg_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intra_cluster_distance(embeddings, clusters, centroids):\n",
    "    total_distance = 0\n",
    "    for i, label in enumerate(clusters):\n",
    "        if label != -1 and label < len(centroids):\n",
    "            cluster_center = centroids[label]\n",
    "            distance = np.linalg.norm(embeddings[i] - cluster_center)\n",
    "            total_distance += distance \n",
    "    return total_distance / np.sum(clusters != -1)\n",
    "\n",
    "\n",
    "print(intra_cluster_distance(kpca_test_embeddings, test_clusters, kmeans.cluster_centers_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = pd.DataFrame(combined_kpca_embeddings_3d, columns=['Component 1', 'Component 2', 'Component 3'])\n",
    "plot_df['cluster'] = combined_clusters\n",
    "\n",
    "# 3D Plotting\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "scatter = ax.scatter(plot_df['Component 1'], plot_df['Component 2'], plot_df['Component 3'], \n",
    "                     c=plot_df['cluster'], cmap='tab10', s=50, alpha=0.6, edgecolor='w')\n",
    "\n",
    "ax.set_xlabel('Component 1')\n",
    "ax.set_ylabel('Component 2')\n",
    "ax.set_zlabel('Component 3')\n",
    "plt.title('3D Clustering of Books')\n",
    "\n",
    "legend1 = ax.legend(*scatter.legend_elements(), title=\"Cluster\")\n",
    "ax.add_artist(legend1)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "goodreads",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
