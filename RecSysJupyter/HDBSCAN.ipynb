{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import faiss  \n",
    "import pickle\n",
    "import umap\n",
    "from sklearn.metrics import davies_bouldin_score, calinski_harabasz_score, silhouette_score\n",
    "from sklearn.preprocessing import normalize\n",
    "from itertools import product \n",
    "import random\n",
    "from joblib import Parallel, delayed\n",
    "import hdbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)  \n",
    "sns.set_theme(style=\"white\", palette=\"muted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    books_list = []\n",
    "\n",
    "    with open('../Pickle/books.pkl', 'rb') as file:\n",
    "        while True:\n",
    "            try:\n",
    "                chunk = pickle.load(file)\n",
    "                books_list.append(chunk)\n",
    "            except EOFError:\n",
    "                break  \n",
    "    books = pd.concat(books_list, ignore_index=True)\n",
    "    books = books.drop_duplicates(subset='title', keep='first')\n",
    "    embedding_matrix = np.vstack(books['embeddings'].values)\n",
    "    return books, embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_umap(embeddings, n_components=10, n_neighbors=300, min_dist=0.0):\n",
    "    embeddings = np.asarray(embeddings, dtype=np.float32)  \n",
    "\n",
    "    umap_model = umap.UMAP(\n",
    "        n_components=n_components,\n",
    "        n_neighbors=n_neighbors,\n",
    "        min_dist=min_dist,\n",
    "        metric='cosine',\n",
    "        low_memory=True, \n",
    "        random_state = 42\n",
    "    )\n",
    "    \n",
    "    return umap_model.fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_clusters_to_books(books, soft_clusters, embeddings, top_n=5):\n",
    "    \"\"\"\n",
    "    Return a DataFrame with only book_id, embeddings, and top N cluster memberships.\n",
    "    \n",
    "    Parameters:\n",
    "    - books: Original books DataFrame. Only the 'book_id' column is used here.\n",
    "    - soft_clusters: Soft cluster membership vectors (probabilities for each cluster).\n",
    "    - embeddings: The UMAP normalized embeddings for each book.\n",
    "    - top_n: Number of top clusters to keep.\n",
    "    \n",
    "    Returns:\n",
    "    - clustered_books: A simplified DataFrame with book_id, embedding, and top_clusters.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert soft_clusters to a NumPy array if not already\n",
    "    if not isinstance(soft_clusters, np.ndarray):\n",
    "        soft_clusters = np.array(soft_clusters)\n",
    "\n",
    "    # Get the top N clusters and their probabilities for each book\n",
    "    top_clusters_list = []\n",
    "    for cluster_vector in soft_clusters:\n",
    "        top_indices = np.argsort(cluster_vector)[::-1][:top_n]\n",
    "        top_probs = cluster_vector[top_indices]\n",
    "        top_clusters = list(zip(top_indices, top_probs))\n",
    "        top_clusters_list.append(top_clusters)\n",
    "    \n",
    "    # Create a new DataFrame with just the needed columns\n",
    "    clustered_books = pd.DataFrame({\n",
    "        'book_id': books['book_id'].values,\n",
    "        'embedding': [embedding.tolist() for embedding in embeddings],  # Convert arrays to lists\n",
    "        'top_clusters': top_clusters_list\n",
    "    })\n",
    "    \n",
    "    return clustered_books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_hdbscan_clustering(embeddings, alpha=0.5, beta=0.5, n_trials=5, n_jobs=-1):\n",
    "    \"\"\"\n",
    "    Perform HDBSCAN clustering on the given embeddings using soft clustering (probabilistic membership vectors).\n",
    "    This function avoids precomputing the distance matrix to save memory.\n",
    "\n",
    "    Args:\n",
    "        embeddings (numpy.ndarray): The normalized embeddings (e.g., UMAP embeddings) of the books or items to cluster.\n",
    "        alpha (float, optional): Weight for the Davies-Bouldin Index in the combined score. Default is 0.5.\n",
    "        beta (float, optional): Weight for the Calinski-Harabasz Index in the combined score. Default is 0.5.\n",
    "        n_trials (int, optional): The number of random hyperparameter combinations to try. Default is 5.\n",
    "        n_jobs (int, optional): The number of jobs to run in parallel. Default is -1 (all cores).\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - best_soft_clusters (numpy.ndarray): The best soft clusters, each element contains the membership \n",
    "              probabilities for each cluster.\n",
    "            - best_hard_clusters (numpy.ndarray): The best hard cluster labels (assigned clusters).\n",
    "            - best_clusterer (hdbscan.HDBSCAN): The best fitted HDBSCAN model used to generate the soft clusters.\n",
    "            - best_db_score (float): The Davies-Bouldin score for the best clustering.\n",
    "            - best_ch_score (float): The Calinski-Harabasz score for the best clustering.\n",
    "            - best_combined_score (float): The combined score for the best clustering.\n",
    "            - best_params (dict): The hyperparameters that gave the best score.\n",
    "    \"\"\"\n",
    "    # Define hyperparameter search space\n",
    "    min_cluster_sizes = [100, 90, 80]\n",
    "    min_samples_list = [50, 60, 70]\n",
    "    cluster_selection_epsilons = [0.1, 0.5]\n",
    "\n",
    "    # Generate all possible hyperparameter combinations\n",
    "    all_param_combinations = list(product(min_cluster_sizes, min_samples_list, cluster_selection_epsilons))\n",
    "\n",
    "    # Sample n_trials parameter combinations\n",
    "    sampled_combinations = random.sample(all_param_combinations, min(n_trials, len(all_param_combinations)))\n",
    "\n",
    "    # Function to evaluate a single hyperparameter combination\n",
    "    def evaluate_params(min_cluster_size, min_samples, cluster_selection_epsilon):\n",
    "        clusterer = hdbscan.HDBSCAN(\n",
    "            min_cluster_size=min_cluster_size,\n",
    "            min_samples=min_samples,\n",
    "            cluster_selection_epsilon=cluster_selection_epsilon,\n",
    "            metric='euclidean', \n",
    "            prediction_data=True,\n",
    "            core_dist_n_jobs=n_jobs,  # Use multiple cores for distance computations\n",
    "            cluster_selection_method='leaf'\n",
    "        )\n",
    "        clusterer.fit(embeddings)\n",
    "\n",
    "        # Get the soft clusters (membership vectors)\n",
    "        soft_clusters = hdbscan.prediction.all_points_membership_vectors(clusterer)\n",
    "\n",
    "        # Compute clustering scores based on hard clusters (labels_)\n",
    "        if len(soft_clusters) > 0:\n",
    "            db_index = davies_bouldin_score(embeddings, clusterer.labels_)\n",
    "            ch_index = calinski_harabasz_score(embeddings, clusterer.labels_)\n",
    "        else:\n",
    "            db_index, ch_index = float(\"inf\"), 0\n",
    "\n",
    "        # Calculate combined score\n",
    "        combined_score = alpha * (1 / db_index) + beta * ch_index\n",
    "\n",
    "        # Print the parameter combination and scores\n",
    "        print(f\"min_cluster_size={min_cluster_size}, min_samples={min_samples}, epsilon={cluster_selection_epsilon}, DB={db_index:.3f}, CH={ch_index:.3f}, Combined={combined_score:.3f}\")\n",
    "\n",
    "        return combined_score, db_index, ch_index, soft_clusters, clusterer.labels_, clusterer, (min_cluster_size, min_samples, cluster_selection_epsilon)\n",
    "\n",
    "    # Evaluate all parameter combinations in parallel\n",
    "    results = Parallel(n_jobs=n_jobs)(\n",
    "        delayed(evaluate_params)(min_cluster_size, min_samples, cluster_selection_epsilon)\n",
    "        for min_cluster_size, min_samples, cluster_selection_epsilon in sampled_combinations\n",
    "    )\n",
    "\n",
    "    # Find the best result\n",
    "    best_index = np.argmax([result[0] for result in results])\n",
    "    best_combined_score, best_db_score, best_ch_score, best_soft_clusters, best_hard_clusters, best_clusterer, best_params = results[best_index]\n",
    "\n",
    "    # Print the best hyperparameters and scores\n",
    "    print(\"\\nBest Hyperparameters:\")\n",
    "    print(f\"min_cluster_size={best_params[0]}, min_samples={best_params[1]}, epsilon={best_params[2]}\")\n",
    "    print(\"Best Combined Score:\", best_combined_score)\n",
    "    print(\"Best Davies-Bouldin Score:\", best_db_score)\n",
    "    print(\"Best Calinski-Harabasz Score:\", best_ch_score)\n",
    "\n",
    "    return best_soft_clusters, best_hard_clusters, best_clusterer, best_db_score, best_ch_score, best_combined_score, best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "books, embedding_matrix = load_data()\n",
    "scaler = StandardScaler()\n",
    "scaled_embeddings = scaler.fit_transform(embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# umap_embeddings = apply_umap(scaled_embeddings)\n",
    "umap_embeddings = pd.read_pickle('../Pickle/umap_embeddings.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#umap_embeddings_normalized = normalize(umap_embeddings, norm='l2', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Hyperparameters:\n",
      "min_cluster_size=100, min_samples=50, epsilon=0.5\n",
      "Best Combined Score: 647.888597436619\n",
      "Best Davies-Bouldin Score: 0.7294188426377485\n",
      "Best Calinski-Harabasz Score: 1294.4062404345182\n"
     ]
    }
   ],
   "source": [
    "best_soft_clusters, best_hard_clusters, best_clusterer, best_db_score, best_ch_score, best_combined_score, best_params = perform_hdbscan_clustering(umap_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(umap_embeddings.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_books = assign_clusters_to_books(books, best_soft_clusters, umap_embeddings, top_n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_id_to_index = {book_id: idx for idx, book_id in enumerate(books['book_id'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = umap_embeddings.shape[1]\n",
    "faiss_index = faiss.IndexFlatL2(dimension)\n",
    "faiss_index.add(umap_embeddings)\n",
    "with open('../Pickle/umap_embeddings.pkl', 'wb') as f:\n",
    "    pickle.dump(umap_embeddings, f)\n",
    "faiss.write_index(faiss_index, '../Pickle/faiss_index.bin')\n",
    "with open('../Pickle/book_id_to_index.pkl', 'wb') as f:\n",
    "    pickle.dump(book_id_to_index, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>embedding</th>\n",
       "      <th>top_clusters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[0.4171278774738312, 0.10337015986442566, 0.30...</td>\n",
       "      <td>[(32, 1.0), (82, 3.516317889250751e-305), (190...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "      <td>[0.3890656530857086, 0.08596204966306686, 0.30...</td>\n",
       "      <td>[(199, 0.02683962260000989), (116, 0.005909768...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40</td>\n",
       "      <td>[0.3129916787147522, 0.0636841356754303, 0.224...</td>\n",
       "      <td>[(175, 0.05767255857016169), (174, 0.032773852...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>[0.2904050052165985, 0.14248579740524292, 0.32...</td>\n",
       "      <td>[(83, 0.07605937165158964), (223, 0.0084628273...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48</td>\n",
       "      <td>[0.3875168561935425, 0.019565841183066368, 0.3...</td>\n",
       "      <td>[(58, 0.00022819556134684034), (30, 0.00017583...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454493</th>\n",
       "      <td>36483546</td>\n",
       "      <td>[0.396977961063385, 0.06940219551324844, 0.357...</td>\n",
       "      <td>[(214, 0.029483059832237285), (204, 0.01112924...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454494</th>\n",
       "      <td>36488099</td>\n",
       "      <td>[0.41653749346733093, -0.05733920633792877, 0....</td>\n",
       "      <td>[(244, 0.050482147865868986), (248, 0.00603390...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454495</th>\n",
       "      <td>36491811</td>\n",
       "      <td>[0.38446611166000366, -0.04149968549609184, 0....</td>\n",
       "      <td>[(263, 0.0036537117744564547), (237, 0.0013087...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454496</th>\n",
       "      <td>36494299</td>\n",
       "      <td>[0.4507542848587036, 0.21118517220020294, 0.27...</td>\n",
       "      <td>[(4, 0.7674472088737923), (16, 0.0022876522288...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454497</th>\n",
       "      <td>36524503</td>\n",
       "      <td>[0.3825613260269165, 0.04092301055788994, 0.30...</td>\n",
       "      <td>[(233, 0.00021163988864113164), (58, 0.0001864...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>454498 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         book_id                                          embedding  \\\n",
       "0              1  [0.4171278774738312, 0.10337015986442566, 0.30...   \n",
       "1             27  [0.3890656530857086, 0.08596204966306686, 0.30...   \n",
       "2             40  [0.3129916787147522, 0.0636841356754303, 0.224...   \n",
       "3             45  [0.2904050052165985, 0.14248579740524292, 0.32...   \n",
       "4             48  [0.3875168561935425, 0.019565841183066368, 0.3...   \n",
       "...          ...                                                ...   \n",
       "454493  36483546  [0.396977961063385, 0.06940219551324844, 0.357...   \n",
       "454494  36488099  [0.41653749346733093, -0.05733920633792877, 0....   \n",
       "454495  36491811  [0.38446611166000366, -0.04149968549609184, 0....   \n",
       "454496  36494299  [0.4507542848587036, 0.21118517220020294, 0.27...   \n",
       "454497  36524503  [0.3825613260269165, 0.04092301055788994, 0.30...   \n",
       "\n",
       "                                             top_clusters  \n",
       "0       [(32, 1.0), (82, 3.516317889250751e-305), (190...  \n",
       "1       [(199, 0.02683962260000989), (116, 0.005909768...  \n",
       "2       [(175, 0.05767255857016169), (174, 0.032773852...  \n",
       "3       [(83, 0.07605937165158964), (223, 0.0084628273...  \n",
       "4       [(58, 0.00022819556134684034), (30, 0.00017583...  \n",
       "...                                                   ...  \n",
       "454493  [(214, 0.029483059832237285), (204, 0.01112924...  \n",
       "454494  [(244, 0.050482147865868986), (248, 0.00603390...  \n",
       "454495  [(263, 0.0036537117744564547), (237, 0.0013087...  \n",
       "454496  [(4, 0.7674472088737923), (16, 0.0022876522288...  \n",
       "454497  [(233, 0.00021163988864113164), (58, 0.0001864...  \n",
       "\n",
       "[454498 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustered_books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Pickle/clustered_books.pkl', 'wb') as f:\n",
    "    pickle.dump(clustered_books, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Compactness: 0.0514\n",
      "Average Separation: 0.1408\n",
      "Outliers: 0 / 454498\n",
      "Percentage of Outliers: 0.00%\n",
      "Davies-Bouldin Index: 0.7294188426377485\n",
      "Calinski-Harabasz Index: 1294.4062404345182\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 36\u001b[0m\n\u001b[0;32m     34\u001b[0m ch_score \u001b[38;5;241m=\u001b[39m calinski_harabasz_score(umap_embeddings, best_hard_clusters)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalinski-Harabasz Index: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mch_score\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 36\u001b[0m sh \u001b[38;5;241m=\u001b[39m \u001b[43msilhouette_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mumap_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbest_hard_clusters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSilhouette Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msh\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\maddy\\anaconda3\\envs\\goodreads\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\maddy\\anaconda3\\envs\\goodreads\\Lib\\site-packages\\sklearn\\metrics\\cluster\\_unsupervised.py:141\u001b[0m, in \u001b[0;36msilhouette_score\u001b[1;34m(X, labels, metric, sample_size, random_state, **kwds)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    140\u001b[0m         X, labels \u001b[38;5;241m=\u001b[39m X[indices], labels[indices]\n\u001b[1;32m--> 141\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(\u001b[43msilhouette_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\maddy\\anaconda3\\envs\\goodreads\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\maddy\\anaconda3\\envs\\goodreads\\Lib\\site-packages\\sklearn\\metrics\\cluster\\_unsupervised.py:305\u001b[0m, in \u001b[0;36msilhouette_samples\u001b[1;34m(X, labels, metric, **kwds)\u001b[0m\n\u001b[0;32m    301\u001b[0m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetric\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m metric\n\u001b[0;32m    302\u001b[0m reduce_func \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(\n\u001b[0;32m    303\u001b[0m     _silhouette_reduce, labels\u001b[38;5;241m=\u001b[39mlabels, label_freqs\u001b[38;5;241m=\u001b[39mlabel_freqs\n\u001b[0;32m    304\u001b[0m )\n\u001b[1;32m--> 305\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpairwise_distances_chunked\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreduce_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    306\u001b[0m intra_clust_dists, inter_clust_dists \u001b[38;5;241m=\u001b[39m results\n\u001b[0;32m    307\u001b[0m intra_clust_dists \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(intra_clust_dists)\n",
      "File \u001b[1;32mc:\\Users\\maddy\\anaconda3\\envs\\goodreads\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2172\u001b[0m, in \u001b[0;36mpairwise_distances_chunked\u001b[1;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[0;32m   2170\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2171\u001b[0m     X_chunk \u001b[38;5;241m=\u001b[39m X[sl]\n\u001b[1;32m-> 2172\u001b[0m D_chunk \u001b[38;5;241m=\u001b[39m \u001b[43mpairwise_distances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (X \u001b[38;5;129;01mis\u001b[39;00m Y \u001b[38;5;129;01mor\u001b[39;00m Y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m PAIRWISE_DISTANCE_FUNCTIONS\u001b[38;5;241m.\u001b[39mget(\n\u001b[0;32m   2174\u001b[0m     metric, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2175\u001b[0m ) \u001b[38;5;129;01mis\u001b[39;00m euclidean_distances:\n\u001b[0;32m   2176\u001b[0m     \u001b[38;5;66;03m# zeroing diagonal, taking care of aliases of \"euclidean\",\u001b[39;00m\n\u001b[0;32m   2177\u001b[0m     \u001b[38;5;66;03m# i.e. \"l2\"\u001b[39;00m\n\u001b[0;32m   2178\u001b[0m     D_chunk\u001b[38;5;241m.\u001b[39mflat[sl\u001b[38;5;241m.\u001b[39mstart :: _num_samples(X) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\maddy\\anaconda3\\envs\\goodreads\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\maddy\\anaconda3\\envs\\goodreads\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2375\u001b[0m, in \u001b[0;36mpairwise_distances\u001b[1;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[0;32m   2372\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m distance\u001b[38;5;241m.\u001b[39msquareform(distance\u001b[38;5;241m.\u001b[39mpdist(X, metric\u001b[38;5;241m=\u001b[39mmetric, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds))\n\u001b[0;32m   2373\u001b[0m     func \u001b[38;5;241m=\u001b[39m partial(distance\u001b[38;5;241m.\u001b[39mcdist, metric\u001b[38;5;241m=\u001b[39mmetric, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m-> 2375\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_parallel_pairwise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\maddy\\anaconda3\\envs\\goodreads\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:1893\u001b[0m, in \u001b[0;36m_parallel_pairwise\u001b[1;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[0;32m   1890\u001b[0m X, Y, dtype \u001b[38;5;241m=\u001b[39m _return_float_dtype(X, Y)\n\u001b[0;32m   1892\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m effective_n_jobs(n_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m-> 1893\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1895\u001b[0m \u001b[38;5;66;03m# enforce a threading backend to prevent data communication overhead\u001b[39;00m\n\u001b[0;32m   1896\u001b[0m fd \u001b[38;5;241m=\u001b[39m delayed(_dist_wrapper)\n",
      "File \u001b[1;32mc:\\Users\\maddy\\anaconda3\\envs\\goodreads\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\maddy\\anaconda3\\envs\\goodreads\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:372\u001b[0m, in \u001b[0;36meuclidean_distances\u001b[1;34m(X, Y, Y_norm_squared, squared, X_norm_squared)\u001b[0m\n\u001b[0;32m    366\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m Y_norm_squared\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m (\u001b[38;5;241m1\u001b[39m, Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m    367\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    368\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncompatible dimensions for Y of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mY\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    369\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mY_norm_squared of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moriginal_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    370\u001b[0m         )\n\u001b[1;32m--> 372\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_euclidean_distances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_norm_squared\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_norm_squared\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msquared\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\maddy\\anaconda3\\envs\\goodreads\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:410\u001b[0m, in \u001b[0;36m_euclidean_distances\u001b[1;34m(X, Y, X_norm_squared, Y_norm_squared, squared)\u001b[0m\n\u001b[0;32m    408\u001b[0m     distances \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m XX\n\u001b[0;32m    409\u001b[0m     distances \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m YY\n\u001b[1;32m--> 410\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaximum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdistances\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdistances\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    412\u001b[0m \u001b[38;5;66;03m# Ensure that distances between vectors and themselves are set to 0.0.\u001b[39;00m\n\u001b[0;32m    413\u001b[0m \u001b[38;5;66;03m# This may not be the case due to floating point rounding errors.\u001b[39;00m\n\u001b[0;32m    414\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m Y:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "compactness = []\n",
    "for label in set(best_hard_clusters):\n",
    "    if label != -1:\n",
    "        cluster_points = umap_embeddings[best_hard_clusters == label]\n",
    "        centroid = cluster_points.mean(axis=0)\n",
    "        distances = euclidean_distances(cluster_points, centroid.reshape(1, -1))\n",
    "        compactness.append(np.mean(distances))\n",
    "\n",
    "separation = []\n",
    "cluster_centroids = [\n",
    "    umap_embeddings[best_hard_clusters == label].mean(axis=0)\n",
    "    for label in set(best_hard_clusters) if label != -1\n",
    "]\n",
    "\n",
    "for i in range(len(cluster_centroids)):\n",
    "    for j in range(i + 1, len(cluster_centroids)):\n",
    "        dist = euclidean_distances(\n",
    "            [cluster_centroids[i]], [cluster_centroids[j]]\n",
    "        )[0][0]\n",
    "        separation.append(dist)\n",
    "\n",
    "print(f\"Average Compactness: {np.mean(compactness):.4f}\")\n",
    "print(f\"Average Separation: {np.mean(separation):.4f}\")\n",
    "\n",
    "total_points = len(best_hard_clusters)\n",
    "outlier_points = np.sum(best_hard_clusters == -1)\n",
    "outlier_percentage = (outlier_points / total_points) * 100\n",
    "print(f\"Outliers: {outlier_points} / {total_points}\")\n",
    "print(f\"Percentage of Outliers: {outlier_percentage:.2f}%\")\n",
    "dbi_score = davies_bouldin_score(umap_embeddings, best_hard_clusters)\n",
    "print(f\"Davies-Bouldin Index: {dbi_score}\")\n",
    "ch_score = calinski_harabasz_score(umap_embeddings, best_hard_clusters)\n",
    "print(f\"Calinski-Harabasz Index: {ch_score}\")\n",
    "sh = silhouette_score(umap_embeddings, best_hard_clusters)\n",
    "print(f\"Silhouette Score: {sh}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "umap_embeddings_2d = apply_umap(scaled_embeddings, n_components=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_indices = best_hard_clusters != -1\n",
    "filtered_embeddings_2d = umap_embeddings_2d[filtered_indices]\n",
    "filtered_clusters = best_hard_clusters[filtered_indices]\n",
    "df_plot_2d = pd.DataFrame({\n",
    "    'UMAP1': filtered_embeddings_2d[:, 0],\n",
    "    'UMAP2': filtered_embeddings_2d[:, 1],\n",
    "    'Cluster': filtered_clusters\n",
    "})\n",
    "fig = px.scatter(\n",
    "    df_plot_2d,\n",
    "    x='UMAP1',\n",
    "    y='UMAP2',\n",
    "    color='Cluster',\n",
    "    title='2D UMAP Embeddings Coloured by Cluster',\n",
    "    opacity=0.7\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title='UMAP Dimension 1',\n",
    "    yaxis_title='UMAP Dimension 2'\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "sns.scatterplot(\n",
    "    x=filtered_embeddings_2d[:, 0],\n",
    "    y=filtered_embeddings_2d[:, 1],\n",
    "    hue=filtered_clusters,\n",
    "    palette='tab10',\n",
    "    alpha=0.7,\n",
    "    legend = False\n",
    ")\n",
    "plt.title('2D Plot of Embeddings and Clusters', fontsize=16)\n",
    "plt.xlabel('UMAP Dimension 1')\n",
    "plt.ylabel('UMAP Dimension 2')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "sns.kdeplot(\n",
    "    x=filtered_embeddings_2d[:, 0],\n",
    "    y=filtered_embeddings_2d[:, 1],\n",
    "    fill=True,\n",
    "    cmap='viridis',  \n",
    "    alpha=0.5\n",
    ")\n",
    "\n",
    "plt.title('Density Plot of UMAP 2D Embeddings')\n",
    "plt.xlabel('UMAP Dimension 1')\n",
    "plt.ylabel('UMAP Dimension 2')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "sns.kdeplot(\n",
    "    x=filtered_embeddings_2d[:, 0],\n",
    "    y=filtered_embeddings_2d[:, 1],\n",
    "    hue=filtered_clusters,\n",
    "    fill=True,\n",
    "    alpha=0.5,\n",
    "    palette='tab10',\n",
    "    legend=False \n",
    ")\n",
    "\n",
    "plt.title('Density Plot of UMAP 2D Embeddings by Cluster')\n",
    "plt.xlabel('UMAP Dimension 1')\n",
    "plt.ylabel('UMAP Dimension 2')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(filtered_clusters, return_counts=True)\n",
    "cluster_sizes = dict(zip(unique, counts))\n",
    "df = pd.DataFrame({\n",
    "    'Cluster': list(cluster_sizes.keys()),\n",
    "    'Count': list(cluster_sizes.values())\n",
    "})\n",
    "plt.figure(figsize=(50, 6))\n",
    "sns.barplot(data=df, x='Cluster', y='Count', hue='Cluster', palette='viridis', dodge=False, legend=False)\n",
    "plt.title('Cluster Sizes (With Outliers)', fontsize=16)\n",
    "plt.xlabel('Cluster Label', fontsize=14)\n",
    "plt.ylabel('Number of Points', fontsize=14)\n",
    "plt.xticks(rotation=0, fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_sizes = [np.sum(best_hard_clusters == label) for label in set(best_hard_clusters) if label != -1]\n",
    "plt.hist(cluster_sizes, bins=10, color='skyblue', edgecolor='black')\n",
    "plt.title('Cluster Size Distribution')\n",
    "plt.xlabel('Cluster Size')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "goodreads",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
