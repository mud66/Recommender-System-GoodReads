{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATv2Conv\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "from sklearn.metrics import mean_absolute_error, root_mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def set_random_seed(seed_value):\n",
    "    \"\"\"Set the random seed for reproducibility.\"\"\"\n",
    "    random.seed(seed_value)  # Set the seed for Python's random module\n",
    "    np.random.seed(seed_value)  # Set the seed for NumPy\n",
    "    torch.manual_seed(seed_value)  # Set the seed for PyTorch CPU\n",
    "    torch.cuda.manual_seed(seed_value)  # Set the seed for PyTorch\n",
    "    torch.cuda.manual_seed_all(seed_value)  # Set the seed for all GPUs\n",
    "    torch.backends.cudnn.deterministic = True  # Ensure deterministic behavior on GPU\n",
    "    torch.backends.cudnn.benchmark = False  # Turn off benchmarks for reproducibility\n",
    "\n",
    "# Set a specific random seed value (e.g., 42)\n",
    "set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "def load_data():\n",
    "    reviews = pd.read_pickle('../Pickle/reviews.pkl')\n",
    "    books = pd.read_pickle('../Pickle/books.pkl')\n",
    "    read = pd.read_pickle('../Pickle/read.pkl')\n",
    "    user_genres = pd.read_pickle('../Pickle/user_most_common_genres.pkl')\n",
    "    review_embeddings = pd.read_pickle('../Pickle/review_embeddings.pkl')\n",
    "    review_sentiment = pd.read_pickle('../Pickle/review_score.pkl')\n",
    "    imputed = pd.read_pickle('../Pickle/imputed_ratings.pkl')\n",
    "    return reviews, books, read, user_genres, review_embeddings, review_sentiment, imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(ratings_data, user_genres, test_size=0.1, val_size=0.15, random_state=42):\n",
    "    # Merge the ratings_data and user_genres on user_id to get the most common genres for users\n",
    "    merged_data = ratings_data.merge(user_genres[['user_id', 'most_common_genres']], on='user_id', how='inner')\n",
    "\n",
    "    # Identify users and books that appear only once in the dataset\n",
    "    user_counts = merged_data['user_id'].value_counts()\n",
    "    book_counts = merged_data['book_id'].value_counts()\n",
    "\n",
    "    # Find interactions where user or book appears only once\n",
    "    single_interactions = merged_data[\n",
    "        merged_data['user_id'].isin(user_counts[user_counts == 1].index) | \n",
    "        merged_data['book_id'].isin(book_counts[book_counts == 1].index)\n",
    "    ]\n",
    "\n",
    "    # Remove those interactions from the main dataset\n",
    "    remaining_interactions = merged_data[~merged_data.index.isin(single_interactions.index)]\n",
    "\n",
    "    # Split the remaining interactions into train, validation, and test\n",
    "    train_df, temp_data = train_test_split(remaining_interactions, test_size=test_size+val_size, random_state=random_state)\n",
    "    val_data, test_data = train_test_split(temp_data, test_size=test_size/(test_size+val_size), random_state=random_state)\n",
    "\n",
    "    # Add the single interactions to the training set\n",
    "    train_data = pd.concat([train_df, single_interactions], ignore_index=True)\n",
    "\n",
    "    return train_data, val_data, test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize ID mappings for users and books\n",
    "def initialize_id_mappings(combined_data):\n",
    "    unique_user_ids = set(combined_data['user_id'])\n",
    "    unique_book_ids = set(combined_data['book_id'])\n",
    "\n",
    "    user_id_to_index = {user_id: idx for idx, user_id in enumerate(unique_user_ids)}\n",
    "    book_id_to_index = {book_id: idx for idx, book_id in enumerate(unique_book_ids)}\n",
    "\n",
    "    return user_id_to_index, book_id_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "\n",
    "def balance_ratings(df, target_column='rating', target_count=12000):\n",
    "    balanced_data = []\n",
    "    \n",
    "    for rating in df[target_column].unique():\n",
    "        class_data = df[df[target_column] == rating]\n",
    "        original_data = class_data.copy()  # Preserve original ratings\n",
    "        \n",
    "        if len(class_data) < target_count:\n",
    "            # Oversample\n",
    "            class_data_resampled = resample(class_data, replace=True, n_samples=target_count, random_state=42)\n",
    "            \n",
    "            # Identify new duplicate rows (not in original data)\n",
    "            duplicated_mask = class_data_resampled.index.isin(original_data.index)\n",
    "            \n",
    "            # Modify only the new duplicate ratings\n",
    "            class_data_resampled.loc[~duplicated_mask, target_column] += np.random.uniform(-0.3, 0.3, size=sum(~duplicated_mask))\n",
    "        else:\n",
    "            # Under-sample\n",
    "            class_data_resampled = resample(class_data, replace=False, n_samples=target_count, random_state=42)\n",
    "        \n",
    "        balanced_data.append(class_data_resampled)\n",
    "    \n",
    "    # Combine and shuffle\n",
    "    balanced_df = pd.concat(balanced_data, axis=0).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    return balanced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log scale ratings\n",
    "def normalise_ratings(train_data, test_data, val_data):\n",
    "    min_rating = train_data['rating'].min()\n",
    "\n",
    "\n",
    "    train_data['rating'] = np.log1p(train_data['rating'])\n",
    "    test_data['rating'] = np.log1p(test_data['rating'])\n",
    "    val_data['rating'] = np.log1p(val_data['rating'])\n",
    "\n",
    "\n",
    "    return train_data, test_data, val_data, min_rating\n",
    "\n",
    "def denormalize_rating(log_scaled_ratings, min_rating):\n",
    "    log_scaled_ratings = np.asarray(log_scaled_ratings, dtype=float)  # Ensure NumPy array\n",
    "\n",
    "    # Reverse log1p transformation\n",
    "    original_ratings = np.expm1(log_scaled_ratings)\n",
    "\n",
    "    # Adjust for minimum rating\n",
    "    if min_rating:\n",
    "        original_ratings += min_rating\n",
    "\n",
    "    # Clip values between 0 and 5\n",
    "    return np.clip(original_ratings, 0, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_book_features(filtered_data, user_id_to_index, book_id_to_index):\n",
    "    # Combine user and book genres to create a unified genre list\n",
    "    unique_genres = sorted(set(filtered_data['filtered_genres'].str.split(',').explode()).union(\n",
    "        set(filtered_data['most_common_genres'].explode())\n",
    "    ))\n",
    "    \n",
    "    # Create a common genre dictionary\n",
    "    genre_dict = {genre: idx for idx, genre in enumerate(unique_genres)}\n",
    "\n",
    "    # Prepare user genre features\n",
    "    user_genre_features = {}\n",
    "    \n",
    "    # Group by user_id and process all genres at once\n",
    "    for user_id, group in filtered_data.groupby('user_id'):\n",
    "        genres = group['most_common_genres'].iloc[0]  # All rows for this user should have the same genres\n",
    "        genre_vector = np.zeros(len(genre_dict))  # Size based on the unified genre list\n",
    "        for genre in genres:\n",
    "            if genre in genre_dict:\n",
    "                genre_vector[genre_dict[genre]] = 1\n",
    "        user_genre_features[user_id_to_index[user_id]] = torch.tensor(genre_vector, dtype=torch.float32)\n",
    "\n",
    "    # Prepare book genre features\n",
    "    book_genre_features = {}\n",
    "    for book_id, group in filtered_data.groupby('book_id'):\n",
    "        genres = group['filtered_genres'].iloc[0].split(',')  # Assuming all rows for this book have the same genres\n",
    "        genre_vector = np.zeros(len(genre_dict))  # Size based on the unified genre list\n",
    "        for genre in genres:\n",
    "            if genre in genre_dict:\n",
    "                genre_vector[genre_dict[genre]] = 1\n",
    "        book_genre_features[book_id_to_index[book_id]] = torch.tensor(genre_vector, dtype=torch.float32)\n",
    "\n",
    "    return user_genre_features, book_genre_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_edge_index_ratings_attributes(df, user_id_to_index, book_id_to_index):\n",
    "    # Map user and book IDs to indices\n",
    "    user_indices = df['user_id'].map(user_id_to_index).dropna().astype(int).values\n",
    "    book_indices = df['book_id'].map(book_id_to_index).dropna().astype(int).values\n",
    "\n",
    "    # Ensure valid mappings\n",
    "    valid_mask = (user_indices >= 0) & (book_indices >= 0)\n",
    "    user_indices = user_indices[valid_mask]\n",
    "    book_indices = book_indices[valid_mask]\n",
    "\n",
    "    # Create edge index\n",
    "    edge_index = torch.tensor([user_indices, book_indices], dtype=torch.long)\n",
    "\n",
    "    # Convert ratings and confidence scores to tensors\n",
    "    ratings_tensor = torch.tensor(df.loc[valid_mask, 'rating'].values, dtype=torch.float32).view(-1, 1)\n",
    "    confidence_tensor = torch.tensor(df.loc[valid_mask, 'confidence_score'].values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "    # Efficiently convert list of NumPy arrays to a tensor\n",
    "    embeddings_np = np.stack(df.loc[valid_mask, 'embeddings'].values)  # Stack directly\n",
    "    embeddings_tensor = torch.from_numpy(embeddings_np).float()  # Convert efficiently\n",
    "\n",
    "    # Concatenate ratings, confidence scores, and embeddings into a single edge attribute tensor\n",
    "    edge_attr = torch.cat([ratings_tensor, confidence_tensor, embeddings_tensor], dim=1)\n",
    "\n",
    "    return edge_index, edge_attr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_objects(train_data, val_data, test_data, user_genre_features, book_genre_features, user_id_to_index, book_id_to_index):\n",
    "    train_edge_index, train_edge_attr = prepare_edge_index_ratings_attributes(\n",
    "        train_data, user_id_to_index, book_id_to_index\n",
    "    )\n",
    "    val_edge_index, val_edge_attr = prepare_edge_index_ratings_attributes(\n",
    "        val_data, user_id_to_index, book_id_to_index\n",
    "    )\n",
    "    test_edge_index, test_edge_attr = prepare_edge_index_ratings_attributes(\n",
    "        test_data, user_id_to_index, book_id_to_index\n",
    "    )\n",
    "\n",
    "    # Convert user and book genre features efficiently\n",
    "    user_embeddings = torch.from_numpy(np.stack(list(user_genre_features.values()))).float()\n",
    "    book_embeddings = torch.from_numpy(np.stack(list(book_genre_features.values()))).float()\n",
    "\n",
    "    # Combine user and book embeddings into node features\n",
    "    node_embeddings = torch.cat([user_embeddings, book_embeddings], dim=0)\n",
    "\n",
    "    # Ensure edge_index is correctly formatted\n",
    "    train_edge_index = train_edge_index.clone().detach()  # Ensure it's a tensor\n",
    "    val_edge_index = val_edge_index.clone().detach()\n",
    "    test_edge_index = test_edge_index.clone().detach()\n",
    "\n",
    "    # Create PyG Data objects\n",
    "    train_data_obj = Data(\n",
    "        x=node_embeddings,\n",
    "        edge_index=train_edge_index,\n",
    "        edge_attr=train_edge_attr  \n",
    "    )\n",
    "\n",
    "    val_data_obj = Data(\n",
    "        x=node_embeddings,\n",
    "        edge_index=val_edge_index,\n",
    "        edge_attr=val_edge_attr\n",
    "    )\n",
    "    \n",
    "    test_data_obj = Data(\n",
    "        x=node_embeddings,\n",
    "        edge_index=test_edge_index,\n",
    "        edge_attr=test_edge_attr\n",
    "    )\n",
    "\n",
    "    return train_data_obj, val_data_obj, test_data_obj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews, books, read, user_genres, review_embeddings, review_sentiment, imputed= load_data()\n",
    "reviews = reviews[reviews['rating'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(reviews, imputed[['user_id', 'book_id', 'rating']], on=['user_id', 'book_id'], how='left', suffixes=('', '_new'))\n",
    "merged_df['rating'] = merged_df['rating_new'].combine_first(merged_df['rating'])\n",
    "final_df = merged_df.drop(columns=['rating_new'])\n",
    "reviews = final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.merge(reviews, review_embeddings, on=\"review_id\", how=\"inner\")  \n",
    "reviews = pd.merge(reviews, review_sentiment, on=\"review_id\", how=\"inner\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "reviews  = reviews[['rating', 'user_id', 'book_id', 'confidence_score', 'embeddings']]   \n",
    "books = books[['book_id', 'title', 'authors', 'filtered_genres', 'average_rating']]\n",
    "data = pd.merge(books, reviews, on='book_id', how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reset_index(drop=True)\n",
    "user_genres = user_genres.reset_index()\n",
    "user_genres = user_genres[user_genres['most_common_genres'].apply(lambda x: len(x) > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data, test_data = split_data(data, user_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id_to_index, book_id_to_index = initialize_id_mappings(data)\n",
    "train_data = balance_ratings(train_data)\n",
    "train_data, test_data, val_data, min_rating = normalise_ratings(train_data, test_data, val_data)\n",
    "user_genre_features, book_genre_features = user_book_features(data, user_id_to_index, book_id_to_index)\n",
    "train_data_obj, val_data_obj, test_data_obj = prepare_data_objects(\n",
    "    train_data, val_data, test_data, user_genre_features, book_genre_features, user_id_to_index, book_id_to_index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('../Pickle/user_id_to_index_gat.pkl', 'wb') as f:\n",
    "    pickle.dump(user_id_to_index, f)\n",
    "\n",
    "with open('../Pickle/book_id_to_index_gat.pkl', 'wb') as f:\n",
    "    pickle.dump(book_id_to_index, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GATModel(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_heads, edge_feature_dim, dropout_rate=0.1):\n",
    "        super(GATModel, self).__init__()\n",
    "        self.dropout_rate = dropout_rate  # Dropout rate\n",
    "\n",
    "        # Define the GAT layers\n",
    "        self.gat1 = GATv2Conv(in_channels, hidden_channels, heads=num_heads, edge_dim=edge_feature_dim)\n",
    "        self.gat2 = GATv2Conv(hidden_channels * num_heads, hidden_channels, heads=num_heads, edge_dim=edge_feature_dim)\n",
    "        self.gat3 = GATv2Conv(hidden_channels * num_heads, hidden_channels, heads=num_heads, edge_dim=edge_feature_dim)\n",
    "        self.gat4 = GATv2Conv(hidden_channels * num_heads, hidden_channels, heads=num_heads, edge_dim=edge_feature_dim)\n",
    "        self.gat5 = GATv2Conv(hidden_channels * num_heads, out_channels, heads=num_heads, concat=False, edge_dim=edge_feature_dim)\n",
    "\n",
    "        # Batch Normalization layers\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_channels * num_heads)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_channels * num_heads)\n",
    "        self.bn3 = nn.BatchNorm1d(hidden_channels * num_heads)\n",
    "        self.bn4 = nn.BatchNorm1d(hidden_channels * num_heads)\n",
    "\n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(p=self.dropout_rate)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        x = self.gat1(x, edge_index, edge_attr)\n",
    "        x = self.bn1(x)  # Batch Normalization\n",
    "        x = F.elu(x)  # Activation function\n",
    "        x = self.dropout(x)  # Dropout after activation\n",
    "\n",
    "        x = self.gat2(x, edge_index, edge_attr)\n",
    "        x = self.bn2(x)  \n",
    "        x = F.elu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.gat3(x, edge_index, edge_attr)\n",
    "        x = self.bn3(x) \n",
    "        x = F.elu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.gat4(x, edge_index, edge_attr)\n",
    "        x = self.bn4(x)  \n",
    "        x = F.elu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.gat5(x, edge_index, edge_attr)  \n",
    "\n",
    "       \n",
    "        edge_outputs = torch.sum(x[edge_index[0]] * x[edge_index[1]], dim=-1)  # Index nodes by edge indices\n",
    "\n",
    "        return edge_outputs, x\n",
    "\n",
    "\n",
    "    def predict(self, x, edge_index, edge_attr):\n",
    "        self.eval()  \n",
    "        with torch.no_grad():  \n",
    "            edge_outputs, node_embeddings = self.forward(x, edge_index, edge_attr)\n",
    "            return node_embeddings, edge_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_data_list = [train_data_obj]  \n",
    "test_data_list = [test_data_obj]\n",
    "val_data_list = [val_data_obj]\n",
    "\n",
    "train_loader = DataLoader(train_data_list, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_data_list, batch_size=8, shuffle=False)\n",
    "val_loader = DataLoader(val_data_list, batch_size=8, shuffle=False)\n",
    "\n",
    "all_embeddings = train_data['embeddings'].tolist() + test_data['embeddings'].tolist()\n",
    "\n",
    "all_embeddings = np.array(all_embeddings, dtype=object)\n",
    "\n",
    "embedding_size = len(all_embeddings[0])\n",
    "edge_feature_dim = 1 + 1 + embedding_size  # Rating + Confidence + Embedding Size\n",
    "\n",
    "model = GATModel(\n",
    "    in_channels=train_data_obj.x.shape[1],  # Input features per node\n",
    "    hidden_channels=35,\n",
    "    out_channels=1,\n",
    "    num_heads=30,\n",
    "    edge_feature_dim=edge_feature_dim  # Correct edge feature dimension\n",
    ").to(device) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(predictions, true_values):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(true_values, predictions, alpha=0.5, color='blue', label=\"Predictions vs True\")\n",
    "    plt.plot([min(true_values), max(true_values)], [min(true_values), max(true_values)], 'r--', label='Perfect Prediction')\n",
    "    plt.xlabel('True Ratings')\n",
    "    plt.ylabel('Predicted Ratings')\n",
    "    plt.title('Predicted Ratings vs True Ratings')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience, delta):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.best_loss = float('inf')\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "        self.best_epoch = 0\n",
    "\n",
    "    def __call__(self, val_loss, epoch):\n",
    "        if val_loss < self.best_loss - self.delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "            self.best_epoch = epoch\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "def plot_loss(train_losses, test_losses):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(train_losses, label='Training Loss')\n",
    "    plt.plot(test_losses, label='Test Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Training vs Test Loss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gat(model, train_loader, val_loader, test_loader, num_epochs, lr, device):\n",
    "    optimizer = AdamW(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)  # Learning rate scheduler\n",
    "    criterion = nn.MSELoss()\n",
    "    early_stopping = EarlyStopping(patience=10, delta=0.0001)\n",
    "\n",
    "    all_true_values = []\n",
    "    all_predicted_values = []\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    best_model_state = None\n",
    "    best_epoch = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        num_train_batches = 0\n",
    "\n",
    "        for batch in train_loader:\n",
    "            batch = batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            edge_outputs, embeddings = model(batch.x, batch.edge_index, batch.edge_attr)\n",
    "            edge_outputs = edge_outputs.view(-1, 1)\n",
    "            target = batch.edge_attr[:, 0].view(-1, 1)\n",
    "\n",
    "            all_true_values.extend(target.cpu().numpy())\n",
    "            all_predicted_values.extend(edge_outputs.cpu().detach().numpy())\n",
    "\n",
    "            loss = criterion(edge_outputs, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item()\n",
    "            num_train_batches += 1\n",
    "\n",
    "        average_train_loss = total_train_loss / num_train_batches\n",
    "        train_losses.append(average_train_loss)\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}, Training Loss: {average_train_loss:.4f}')\n",
    "\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        num_val_batches = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                batch = batch.to(device)\n",
    "                val_out, _ = model(batch.x, batch.edge_index, batch.edge_attr)\n",
    "                val_out = val_out.view(-1, 1)\n",
    "                target = batch.edge_attr[:, 0].view(-1, 1)\n",
    "                val_loss = criterion(val_out, target)\n",
    "                total_val_loss += val_loss.item()\n",
    "                num_val_batches += 1\n",
    "\n",
    "        average_val_loss = total_val_loss / num_val_batches\n",
    "        val_losses.append(average_val_loss)\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}, Validation Loss: {average_val_loss:.4f}')\n",
    "\n",
    "        if average_val_loss < early_stopping.best_loss:\n",
    "            best_model_state = model.state_dict()\n",
    "            best_epoch = epoch + 1\n",
    "            torch.save(best_model_state, '../Pickle/gat_model.pth')\n",
    "\n",
    "        early_stopping(average_val_loss, epoch + 1)\n",
    "        if early_stopping.early_stop:\n",
    "            print(f\"Early stopping triggered at epoch {epoch + 1}. Best model was at epoch {best_epoch}.\")\n",
    "            break\n",
    "\n",
    "        scheduler.step()  # Update learning rate\n",
    "\n",
    "    plot_loss(train_losses, val_losses)\n",
    "    model.load_state_dict(torch.load('../Pickle/gat_model.pth'))\n",
    "    print(f\"Loaded best model from epoch {best_epoch} for final evaluation.\")\n",
    "\n",
    "    # Evaluation phase using the test set\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_true = []\n",
    "    all_embeddings = [] \n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            batch = batch.to(device)\n",
    "            test_out, embeddings = model(batch.x, batch.edge_index, batch.edge_attr)\n",
    "            test_out = test_out.view(-1, 1)\n",
    "            target = batch.edge_attr[:, 0].view(-1, 1)\n",
    "            all_preds.append(test_out)\n",
    "            all_true.append(target)\n",
    "            all_embeddings.append(embeddings.cpu().numpy())\n",
    "\n",
    "    all_preds = torch.cat(all_preds, dim=0).cpu().numpy()\n",
    "    all_true = torch.cat(all_true, dim=0).cpu().numpy()\n",
    "    all_embeddings = np.concatenate(all_embeddings, axis=0)\n",
    "\n",
    "    rmse = root_mean_squared_error(all_true, all_preds)\n",
    "    mae = mean_absolute_error(all_true, all_preds)\n",
    "    print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "    print(f\"Mean Absolute Error: {mae:.4f}\")\n",
    "\n",
    "    return rmse, mae, all_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse, mae, all_embeddings = train_gat(model, train_loader, val_loader, test_loader, num_epochs=150, lr=0.0001, device=device)\n",
    "node_embeddings, predicted_ratings = model.predict(test_data_obj.x, test_data_obj.edge_index, test_data_obj.edge_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids = test_data_obj.edge_index[0]  \n",
    "item_ids = test_data_obj.edge_index[1]  \n",
    "true_ratings = test_data_obj.edge_attr[:, 0].cpu().numpy()\n",
    "\n",
    "# Modify predictions to include true ratings\n",
    "predictions = [(uid.item(), iid.item(), true_ratings[idx], predicted_ratings[idx].item()) \n",
    "               for idx, (uid, iid) in enumerate(zip(user_ids, item_ids))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Pickle/gat_embeddings.pkl', 'wb') as f:\n",
    "    pickle.dump(all_embeddings, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall_ndcg_mrr_at_k(predictions, min_rating, k, threshold, item_popularity, num_users):\n",
    "    \"\"\"\n",
    "    Compute Precision@k, Recall@k, nDCG@k, MRR@k, Novelty, Hit Rate, and User Coverage.\n",
    "\n",
    "    Parameters:\n",
    "        predictions (list): List of tuples (user_id, item_id, true_rating, predicted_rating, _).\n",
    "        min_rating (float): Minimum rating value for denormalization.\n",
    "        k (int): Number of recommendations to consider.\n",
    "        threshold (float): Threshold for considering an item as relevant.\n",
    "        item_popularity (dict): Dictionary of item popularity counts.\n",
    "        num_users (int): Total number of users.\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (precision, recall, ndcg, mrr, novelty, hit_rate, user_coverage).\n",
    "    \"\"\"\n",
    "    # Denormalize ratings\n",
    "    denormalized_ratings = [denormalize_rating(est, min_rating) for _, _, _, est, _ in predictions]\n",
    "    denormalized_true_ratings = [denormalize_rating(true_r, min_rating) for _, _, true_r, _, _ in predictions]\n",
    "\n",
    "    denormalized_predictions = [(uid, iid, denormalized_true_ratings[idx], denormalized_ratings[idx], _) \n",
    "                                for idx, (uid, iid, true_r, est, _) in enumerate(predictions)]\n",
    "\n",
    "    # Organize predictions by user\n",
    "    user_est_true = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in denormalized_predictions:\n",
    "        user_est_true[uid].append((iid, est, true_r))\n",
    "\n",
    "    precisions, recalls, ndcgs, mrrs = [], [], [], []\n",
    "    hit_counts = defaultdict(int)  # Track hits for Hit Rate\n",
    "    user_coverage_set = set()  # Track users with at least one recommendation\n",
    "    novelty_scores = []  # Track novelty scores\n",
    "\n",
    "    max_self_info = log2(num_users) if num_users > 0 else 1  # Avoid division by zero\n",
    "\n",
    "    for user_id, user_ratings in user_est_true.items():\n",
    "        # Sort by estimated rating\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        # Get relevant items (ratings >= threshold)\n",
    "        relevant_items = [(iid, est, true_r) for iid, est, true_r in user_ratings if true_r >= threshold]\n",
    "        n_rel = len(relevant_items)\n",
    "\n",
    "        if n_rel == 0:\n",
    "            precisions.append(0)\n",
    "            recalls.append(0)\n",
    "            ndcgs.append(0)\n",
    "            mrrs.append(0)\n",
    "            continue\n",
    "\n",
    "        # Get top-k predictions\n",
    "        top_k = user_ratings[:k]\n",
    "        n_rec_k = sum(est >= threshold for _, est, _ in top_k)\n",
    "        n_rel_and_rec_k = sum((true_r >= threshold) and (est >= threshold) for _, est, true_r in top_k)\n",
    "\n",
    "        # Precision at k\n",
    "        precision = n_rel_and_rec_k / n_rec_k if n_rec_k > 0 else 0\n",
    "        recall = n_rel_and_rec_k / n_rel if n_rel > 0 else 0\n",
    "\n",
    "        # NDCG at k\n",
    "        actual_dcg = sum((2 ** rel - 1) / log2(idx + 2) for idx, (_, _, rel) in enumerate(top_k))\n",
    "        ideal_ratings_sorted = sorted(user_ratings, key=lambda x: x[2], reverse=True)[:k]\n",
    "        ideal_dcg = sum((2 ** rel - 1) / log2(idx + 2) for idx, (_, _, rel) in enumerate(ideal_ratings_sorted))\n",
    "        ndcg = actual_dcg / ideal_dcg if ideal_dcg > 0 else 0\n",
    "\n",
    "        # MRR at k\n",
    "        mrr = 0\n",
    "        for rank, (iid, est, true_r) in enumerate(top_k, start=1):\n",
    "            if true_r >= threshold:\n",
    "                mrr = 1 / rank\n",
    "                break\n",
    "\n",
    "        # Hit Rate\n",
    "        if n_rel_and_rec_k > 0:\n",
    "            hit_counts[user_id] = 1\n",
    "\n",
    "        # User Coverage\n",
    "        if n_rec_k > 0:\n",
    "            user_coverage_set.add(user_id)\n",
    "\n",
    "        # Novelty (normalized to 0-1)\n",
    "        raw_self_info = [-log2(item_popularity.get(iid, 1) / num_users) for iid, _, _ in top_k]\n",
    "        normalized_self_info = [score / max_self_info for score in raw_self_info]\n",
    "        mean_self_info = np.mean(normalized_self_info)\n",
    "        novelty_scores.append(mean_self_info)\n",
    "\n",
    "        # Append the metrics\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        ndcgs.append(ndcg)\n",
    "        mrrs.append(mrr)\n",
    "\n",
    "    # Compute overall metrics\n",
    "    precision = np.mean(precisions)\n",
    "    recall = np.mean(recalls)\n",
    "    ndcg = np.mean(ndcgs)\n",
    "    mrr = np.mean(mrrs)\n",
    "    hit_rate = np.mean(list(hit_counts.values())) if hit_counts else 0\n",
    "    user_coverage = len(user_coverage_set) / len(user_est_true) if user_est_true else 0\n",
    "    novelty = np.mean(novelty_scores) if novelty_scores else 0\n",
    "\n",
    "    return (\n",
    "        precision,\n",
    "        recall,\n",
    "        ndcg,\n",
    "        mrr,\n",
    "        novelty,\n",
    "        hit_rate,\n",
    "        user_coverage\n",
    "    )\n",
    "\n",
    "threshold = 4  # Relevance threshold\n",
    "item_popularity = test_data['book_id'].value_counts().to_dict()\n",
    "num_users = test_ata['user_id'].nunique()\n",
    "\n",
    "# Compute metrics\n",
    "precision, recall, ndcg, mrr, novelty, hit_rate, user_coverage = precision_recall_ndcg_mrr_at_k(\n",
    "    predictions, min_rating=1.0, k=5, threshold=threshold, item_popularity=item_popularity, num_users=num_users\n",
    ")\n",
    "\n",
    "# Print results\n",
    "print(f'Precision@{k}: {precision:.4f}')\n",
    "print(f'Recall@{k}: {recall:.4f}')\n",
    "print(f'nDCG@{k}: {ndcg:.4f}')\n",
    "print(f'MRR@{k}: {mrr:.4f}')\n",
    "print(f'Novelty (0-1): {novelty:.4f}')\n",
    "print(f'Hit Rate: {hit_rate:.4f}')\n",
    "print(f'User Coverage: {user_coverage:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_prediction_histogram(predictions):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.hist(predictions, bins=20, color='skyblue', edgecolor='black')\n",
    "    plt.title('Distribution of Predicted Ratings')\n",
    "    plt.xlabel('Predicted Ratings')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "\n",
    "plot_prediction_histogram(predicted_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_ratings.min().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_ratings.max().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_ratings.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['rating'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def visualize_embeddings_with_clustering(data_obj, embed_type=\"node\", n_clusters=6):\n",
    "    if embed_type == \"node\":\n",
    "        embeddings = data_obj.x.cpu().detach().numpy()\n",
    "        title = \"PCA of Node Embeddings with Clusters\"\n",
    "    else:\n",
    "        embeddings = data_obj.edge_attr.cpu().detach().numpy()\n",
    "        title = \"t-SNE of Edge Embeddings with Clusters\"\n",
    "\n",
    "    if embeddings.shape[1] > 2:  # Apply dimensionality reduction if needed\n",
    "        pca = PCA(n_components=2)\n",
    "        reduced_embeddings = pca.fit_transform(embeddings)\n",
    "    else:\n",
    "        reduced_embeddings = embeddings\n",
    "\n",
    "    # Perform KMeans clustering\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    kmeans.fit(reduced_embeddings)\n",
    "    labels = kmeans.labels_\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(reduced_embeddings[:, 0], reduced_embeddings[:, 1], c=labels, cmap='viridis', alpha=0.7)\n",
    "    \n",
    "    plt.xlabel(\"Component 1\")\n",
    "    plt.ylabel(\"Component 2\")\n",
    "    plt.title(title)\n",
    "    plt.colorbar(label=\"Cluster\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_embeddings_with_clustering(train_data_obj, embed_type=\"edge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_embeddings_with_clustering(train_data_obj, embed_type=\"node\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "def plot_node_embeddings(user_genre_features, book_genre_features):\n",
    "    # Convert user and book genre features into numpy arrays\n",
    "    all_user_features = torch.stack(list(user_genre_features.values())).cpu().numpy()\n",
    "    all_book_features = torch.stack(list(book_genre_features.values())).cpu().numpy()\n",
    "\n",
    "    # Combine user and book features for dimensionality reduction\n",
    "    all_features = np.concatenate([all_user_features, all_book_features], axis=0)\n",
    "\n",
    "    # Option 1: Use PCA for dimensionality reduction\n",
    "    pca = PCA(n_components=2)\n",
    "    reduced_features_pca = pca.fit_transform(all_features)\n",
    "\n",
    "    # Option 2: Use t-SNE for dimensionality reduction (can capture nonlinear relationships)\n",
    "    tsne = TSNE(n_components=2)\n",
    "    reduced_features_tsne = tsne.fit_transform(all_features)\n",
    "\n",
    "    # Plot PCA reduced features\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(reduced_features_pca[:, 0], reduced_features_pca[:, 1], c='blue', label='Embeddings')\n",
    "    plt.title(\"2D Projection of User and Book Features (PCA)\")\n",
    "    plt.xlabel(\"PCA Component 1\")\n",
    "    plt.ylabel(\"PCA Component 2\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot t-SNE reduced features\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(reduced_features_tsne[:, 0], reduced_features_tsne[:, 1], c='red', label='Embeddings')\n",
    "    plt.title(\"2D Projection of User and Book Features (t-SNE)\")\n",
    "    plt.xlabel(\"t-SNE Component 1\")\n",
    "    plt.ylabel(\"t-SNE Component 2\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_node_embeddings(user_genre_features, book_genre_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Plot the distribution of adjusted ratings\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(train_data['rating'], bins=5)\n",
    "plt.title('Distribution of Ratings In GATv2Conv Train Data')\n",
    "plt.xlabel('Adjusted Rating')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Plot the distribution of adjusted ratings\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(test_data['rating'], bins=5)\n",
    "plt.title('Distribution of Ratings In GATv2Conv Test Data')\n",
    "plt.xlabel('Adjusted Rating')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "goodreads",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
