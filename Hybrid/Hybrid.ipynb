{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. if user read < 5 books call content filtering py\n",
    "2.  if user read > 5 books call collaborative ratings py\n",
    "3. if user read > 5 and review > 5  books call collaborative ratings and reviews .py\n",
    "\n",
    "for 1. get 5th rec book and re input into content filtering and get top rec and raplce in oriignal recs\n",
    "same idea for 2 and 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import faiss\n",
    "import numpy as np\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_list = []\n",
    "\n",
    "with open('../Pickle/books.pkl', 'rb') as file:\n",
    "    while True:\n",
    "        try:\n",
    "            chunk = pickle.load(file)\n",
    "            books_list.append(chunk)\n",
    "        except EOFError:\n",
    "            break  # Stop when end of file is reached\n",
    "books = pd.concat(books_list, ignore_index=True)\n",
    "books = books.drop_duplicates(subset='title', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions = pd.read_pickle('../Pickle/interactions.pkl')\n",
    "read = pd.read_pickle('../Pickle/read.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the common book_ids in all three DataFrames\n",
    "valid_book_ids = set(books['book_id'])\n",
    "\n",
    "# Filter each DataFrame to keep only those book_ids\n",
    "interactions = interactions[interactions['book_id'].isin(valid_book_ids)]\n",
    "read = read[read['book_id'].isin(valid_book_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load UMAP embeddings\n",
    "with open('../RecSysJupyter/umap_embeddings.pkl', 'rb') as f:\n",
    "    umap_embeddings = pickle.load(f)\n",
    "\n",
    "# Load FAISS index\n",
    "faiss_index = faiss.read_index('../RecSysJupyter/faiss_index.bin')\n",
    "\n",
    "# Load book_id to index mapping\n",
    "with open('../RecSysJupyter/book_id_to_index.pkl', 'rb') as f:\n",
    "    book_id_to_index = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_books_read = read[read['user_id'] == user_id ]\n",
    "user_num_books = user_books_read['book_id'].nunique()\n",
    "user_reviews = interactions[interactions['user_id']== user_id]\n",
    "user_num_reviews = user_reviews['book_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations_by_cluster(book_id, books=books, umap_embeddings=umap_embeddings, top_n=5, book_id_to_index=book_id_to_index):\n",
    "    if book_id not in book_id_to_index:\n",
    "        print(f\"Warning: {book_id} is not in book_id_to_index.\")  # Print missing book_id\n",
    "        return (\"not in index\")  # Return empty if book_id is not in book_id_to_index\n",
    "\n",
    "    book_idx = book_id_to_index[book_id]\n",
    "    input_book_title = books.loc[books['book_id'] == book_id, 'title'].values[0]\n",
    "\n",
    "    # Search for nearest neighbors using FAISS\n",
    "    distances, indices = faiss_index.search(np.array([umap_embeddings[book_idx]]), top_n + 1)\n",
    "\n",
    "    recommendations = []\n",
    "    for idx, dist in zip(indices[0][1:], distances[0][1:]):  # Exclude the book itself\n",
    "        # Check if the index is within bounds\n",
    "        if idx >= len(books):\n",
    "            print(f\"Warning: Index {idx} is out of bounds for books DataFrame.\")\n",
    "            continue  # Skip if the index is out of bounds\n",
    "\n",
    "        recommended_book = books.iloc[idx]\n",
    "        explanation = f\"Similarity Score: {round(1 / (1 + dist), 3)}\"\n",
    "        recommendations.append({\n",
    "            \"title\": recommended_book[\"title\"],\n",
    "            \"authors\": recommended_book[\"authors\"],\n",
    "            \"cluster\": recommended_book.get(\"cluster\", \"N/A\"),\n",
    "            \"explanation\": explanation\n",
    "        })\n",
    "\n",
    "    return recommendations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_books(model, interactions, user_id, books_read, books, n_recommendations=5):\n",
    "    \"\"\"Recommend top-N books for a specific user or all users using the trained NMF model.\"\"\"\n",
    "    \n",
    "    # Get unique books from the interactions dataset\n",
    "    all_books = interactions['book_id'].unique()\n",
    "    unread_books = list(set(all_books) - set(books_read))\n",
    "\n",
    "    # Predict ratings for unread books\n",
    "    user_predictions = [\n",
    "        (book_id, model.predict(uid=user_id, iid=book_id).est) for book_id in unread_books\n",
    "    ]\n",
    "    \n",
    "    # Sort predictions by estimated rating in descending order\n",
    "    user_predictions.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Get the top-N recommended books and map to title, authors, and rating\n",
    "    top_books = user_predictions[:n_recommendations]\n",
    "    top_books_with_details = []\n",
    "    \n",
    "    for book_id, rating in top_books:\n",
    "        # Lookup the title and authors of the book using the books DataFrame\n",
    "        book_info = books.loc[books['book_id'] == book_id, ['title', 'authors']].values[0]\n",
    "        book_title = book_info[0]\n",
    "        book_authors = book_info[1]\n",
    "        \n",
    "        # Append the book_id, title, authors, and rating to the list\n",
    "        top_books_with_details.append((book_id, book_title, book_authors, rating))\n",
    "        \n",
    "    return {user_id: top_books_with_details}  # Return list of (book_id, title, authors, predicted_rating)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gat2vconv model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 123 has read 22 books. Using collaborative filtering.\n",
      "[(1508, 'Hippolytos', ['Euripides', 'Robert Bagg'], 5), (12973, \"A Winter's Tale: The Wreck of the Florizel\", ['Cassie Brown'], 4.853050560492331), (47609, 'His Mouth Will Taste of Wormwood and Other Stories', ['Poppy Z. Brite'], 4.837640038360307), (1234, 'Shadows and Wind: A View of Modern Vietnam', ['Robert Templer'], 4.717385891621058), (50352, 'A Hunger for Healing: The Twelve Steps as a Classic Model for Christian Spiritual Growth', ['J. Keith Miller'], 4.709044243707063)]\n",
      "[(1508, 'Hippolytos', ['Euripides', 'Robert Bagg'], 5), (12973, \"A Winter's Tale: The Wreck of the Florizel\", ['Cassie Brown'], 4.853050560492331), (47609, 'His Mouth Will Taste of Wormwood and Other Stories', ['Poppy Z. Brite'], 4.837640038360307), (1234, 'Shadows and Wind: A View of Modern Vietnam', ['Robert Templer'], 4.717385891621058), ({'title': 'Radicalism and the Origins of the Vietnamese Revolution', 'authors': ['Hue-Tam Ho Tai'], 'cluster': 'N/A', 'explanation': 'Similarity Score: 0.999'}, 'A Hunger for Healing: The Twelve Steps as a Classic Model for Christian Spiritual Growth')]\n"
     ]
    }
   ],
   "source": [
    "if user_num_books < 5:\n",
    "    print(f\"User {user_id} has read {user_num_books} books. Using content-based filtering.\")\n",
    "    recommendations = []\n",
    "\n",
    "# For each book the user has read, get recommendations\n",
    "    for book_id in user_books_read:\n",
    "        book_recommendations = get_recommendations_by_cluster(book_id)\n",
    "        recommendations.extend(book_recommendations)\n",
    "\n",
    "# Remove duplicate recommendations\n",
    "    unique_recommendations = {rec['title']: rec for rec in recommendations}.values()\n",
    "\n",
    "# Convert to a list for easier handling\n",
    "    unique_recommendations = list(unique_recommendations)\n",
    "\n",
    "# Display the recommendations\n",
    "    for rec in unique_recommendations:\n",
    "        print(f\"Title: {rec['title']}\")\n",
    "        print(f\"Authors: {rec['authors']}\")\n",
    "        print(f\"Cluster: {rec['cluster']}\")\n",
    "        print(f\"Explanation: {rec['explanation']}\")\n",
    "        print() \n",
    "        \n",
    "if user_num_books > 5 and user_num_reviews < 15:\n",
    "\n",
    "    print(f\"User {user_id} has read {user_num_books} books. Using collaborative filtering.\")\n",
    "    best_nmf = joblib.load('../RecSysJupyter/best_nmf_model.pkl')\n",
    "    book_recommendations = recommend_books(best_nmf, interactions, user_id, user_books_read , books)\n",
    "    user_predictions = book_recommendations.get(user_id, [])\n",
    "    print(user_predictions)\n",
    "    fifth_rec = user_predictions[3][0]  # book_id of the 5th recommendation\n",
    "     # Feed it into the get_recommendation_by_cluster function to get 5 new books\n",
    "    new_recommendations = get_recommendations_by_cluster(fifth_rec)\n",
    "        # Take the 1st book from the new recommendations\n",
    "    new_first_rec = new_recommendations[0]\n",
    "        \n",
    "        # Replace the original 5th recommendation with the new first recommendation\n",
    "    user_predictions[4] = (new_first_rec, user_predictions[4][1])  # Keep the original rating\n",
    "        \n",
    "        # Return the updated recommendations for the user\n",
    "    book_recommendations[user_id] = user_predictions[:5]\n",
    "    print(user_predictions)\n",
    "\n",
    "if user_num_books > 5 and user_num_reviews > 15:\n",
    "    print(\"using nmf and gat2vconv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "goodreads",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
