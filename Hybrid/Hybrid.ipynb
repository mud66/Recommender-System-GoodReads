{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. if user read < 5 books call content filtering py\n",
    "2.  if user read > 5 books call collaborative ratings py\n",
    "3. if user read > 5 and review > 5  books call collaborative ratings and reviews .py\n",
    "\n",
    "for 1. get 5th rec book and re input into content filtering and get top rec and raplce in oriignal recs\n",
    "same idea for 2 and 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import faiss\n",
    "import numpy as np\n",
    "import joblib\n",
    "from torch_geometric.nn import GATv2Conv\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_list = []\n",
    "\n",
    "with open('../Pickle/books.pkl', 'rb') as file:\n",
    "    while True:\n",
    "        try:\n",
    "            chunk = pickle.load(file)\n",
    "            books_list.append(chunk)\n",
    "        except EOFError:\n",
    "            break  # Stop when end of file is reached\n",
    "books = pd.concat(books_list, ignore_index=True)\n",
    "books = books.drop_duplicates(subset='title', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions = pd.read_pickle('../Pickle/interactions.pkl')\n",
    "read = pd.read_pickle('../Pickle/read.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_book_ids = set(books['book_id'])\n",
    "interactions = interactions[interactions['book_id'].isin(valid_book_ids)]\n",
    "read = read[read['book_id'].isin(valid_book_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Pickle/umap_embeddings.pkl', 'rb') as f:\n",
    "    umap_embeddings = pickle.load(f)\n",
    "\n",
    "faiss_index = faiss.read_index('../Pickle/faiss_index.bin')\n",
    "\n",
    "with open('../Pickle/book_id_to_index.pkl', 'rb') as f:\n",
    "    book_id_to_index = pickle.load(f)\n",
    "\n",
    "model = torch.load('../Pickle/gat_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_books_read = read[read['user_id'] == user_id ]\n",
    "user_num_books = user_books_read['book_id'].nunique()\n",
    "user_reviews = interactions[interactions['user_id']== user_id]\n",
    "user_num_reviews = user_reviews['book_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_num_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations_by_cluster(book_id, books=books, umap_embeddings=umap_embeddings, top_n=5, book_id_to_index=book_id_to_index):\n",
    "    if book_id not in book_id_to_index:\n",
    "        print(f\"Warning: {book_id} is not in book_id_to_index.\")  # Print missing book_id\n",
    "        return (\"not in index\")  # Return empty if book_id is not in book_id_to_index\n",
    "\n",
    "    book_idx = book_id_to_index[book_id]\n",
    "    input_book_title = books.loc[books['book_id'] == book_id, 'title'].values[0]\n",
    "\n",
    "    # Search for nearest neighbors using FAISS\n",
    "    distances, indices = faiss_index.search(np.array([umap_embeddings[book_idx]]), top_n + 1)\n",
    "\n",
    "    recommendations = []\n",
    "    for idx, dist in zip(indices[0][1:], distances[0][1:]):  # Exclude the book itself\n",
    "        # Check if the index is within bounds\n",
    "        if idx >= len(books):\n",
    "            print(f\"Warning: Index {idx} is out of bounds for books DataFrame.\")\n",
    "            continue  # Skip if the index is out of bounds\n",
    "\n",
    "        recommended_book = books.iloc[idx]\n",
    "        explanation = f\"Similarity Score: {round(1 / (1 + dist), 3)}\"\n",
    "        recommendations.append({\n",
    "            \"title\": recommended_book[\"title\"],\n",
    "            \"authors\": recommended_book[\"authors\"],\n",
    "            \"cluster\": recommended_book.get(\"cluster\", \"N/A\"),\n",
    "            \"explanation\": explanation\n",
    "        })\n",
    "\n",
    "    return recommendations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_books(model, interactions, user_id, books_read, books, n_recommendations=5):\n",
    "    \"\"\"Recommend top-N books for a specific user or all users using the trained NMF model.\"\"\"\n",
    "    \n",
    "    # Get unique books from the interactions dataset\n",
    "    all_books = interactions['book_id'].unique()\n",
    "    unread_books = list(set(all_books) - set(books_read))\n",
    "\n",
    "    # Predict ratings for unread books\n",
    "    user_predictions = [\n",
    "        (book_id, model.predict(uid=user_id, iid=book_id).est) for book_id in unread_books\n",
    "    ]\n",
    "    \n",
    "    # Sort predictions by estimated rating in descending order\n",
    "    user_predictions.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Get the top-N recommended books and map to title, authors, and rating\n",
    "    top_books = user_predictions[:n_recommendations]\n",
    "    top_books_with_details = []\n",
    "    \n",
    "    for book_id, rating in top_books:\n",
    "        # Lookup the title and authors of the book using the books DataFrame\n",
    "        book_info = books.loc[books['book_id'] == book_id, ['title', 'authors']].values[0]\n",
    "        book_title = book_info[0]\n",
    "        book_authors = book_info[1]\n",
    "        \n",
    "        # Append the book_id, title, authors, and rating to the list\n",
    "        top_books_with_details.append((book_id, book_title, book_authors, rating))\n",
    "        \n",
    "    return {user_id: top_books_with_details}  # Return list of (book_id, title, authors, predicted_rating)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using nmf and gat2vconv\n",
      "User 123 has read 22 books. Using collaborative filtering.\n",
      "[(236, 'The Complete Nonsense of Edward Lear', ['Edward Lear'], 5), (461, 'The Inner Life of Martin Frost', ['Paul Auster', 'Glenn Thomas'], 5), (790, 'Rough Guide Directions: London', ['Rob Humphreys'], 5), (941, 'Love As A Foreign Language #5', ['J. Torres', 'Eric  Kim'], 5), (1234, 'Shadows and Wind: A View of Modern Vietnam', ['Robert Templer'], 5)]\n"
     ]
    }
   ],
   "source": [
    "if user_num_books < 5:\n",
    "    print(f\"User {user_id} has read {user_num_books} books. Using content-based filtering.\")\n",
    "    recommendations = []\n",
    "\n",
    "# For each book the user has read, get recommendations\n",
    "    for book_id in user_books_read:\n",
    "        book_recommendations = get_recommendations_by_cluster(book_id)\n",
    "        recommendations.extend(book_recommendations)\n",
    "\n",
    "# Remove duplicate recommendations\n",
    "    unique_recommendations = {rec['title']: rec for rec in recommendations}.values()\n",
    "\n",
    "# Convert to a list for easier handling\n",
    "    unique_recommendations = list(unique_recommendations)\n",
    "\n",
    "# Display the recommendations\n",
    "    for rec in unique_recommendations:\n",
    "        print(f\"Title: {rec['title']}\")\n",
    "        print(f\"Authors: {rec['authors']}\")\n",
    "        print(f\"Cluster: {rec['cluster']}\")\n",
    "        print(f\"Explanation: {rec['explanation']}\")\n",
    "        print() \n",
    "        \n",
    "if user_num_books > 5 and user_num_reviews < 5:\n",
    "\n",
    "    print(f\"User {user_id} has read {user_num_books} books. Using collaborative filtering.\")\n",
    "    best_nmf = joblib.load('../Pickle/best_nmf_model.pkl')\n",
    "    book_recommendations = recommend_books(best_nmf, interactions, user_id, user_books_read , books)\n",
    "    user_predictions = book_recommendations.get(user_id, [])\n",
    "    print(user_predictions)\n",
    "    fifth_rec = user_predictions[3][0]  # book_id of the 5th recommendation\n",
    "     # Feed it into the get_recommendation_by_cluster function to get 5 new books\n",
    "    new_recommendations = get_recommendations_by_cluster(fifth_rec)\n",
    "        # Take the 1st book from the new recommendations\n",
    "    new_first_rec = new_recommendations[0]\n",
    "        \n",
    "        # Replace the original 5th recommendation with the new first recommendation\n",
    "    user_predictions[4] = (new_first_rec, user_predictions[4][1])  # Keep the original rating\n",
    "        \n",
    "        # Return the updated recommendations for the user\n",
    "    book_recommendations[user_id] = user_predictions[:5]\n",
    "    print(user_predictions)\n",
    "\n",
    "if user_num_books > 5 and user_num_reviews > 5:\n",
    "    print(\"using nmf and gat2vconv\")\n",
    "    print(f\"User {user_id} has read {user_num_books} books. Using collaborative filtering.\")\n",
    "    best_nmf = joblib.load('../Pickle/best_nmf_model.pkl')\n",
    "    book_recommendations = recommend_books(best_nmf, interactions, user_id, user_books_read , books)\n",
    "    user_predictions = book_recommendations.get(user_id, [])\n",
    "    print(user_predictions)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "goodreads",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
