{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import faiss\n",
    "import numpy as np\n",
    "import joblib\n",
    "from torch_geometric.nn import GATv2Conv\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_list = []\n",
    "\n",
    "with open('../Pickle/books.pkl', 'rb') as file:\n",
    "    while True:\n",
    "        try:\n",
    "            chunk = pickle.load(file)\n",
    "            books_list.append(chunk)\n",
    "        except EOFError:\n",
    "            break  # Stop when end of file is reached\n",
    "books = pd.concat(books_list, ignore_index=True)\n",
    "books = books.drop_duplicates(subset='title', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions = pd.read_pickle('../Pickle/interactions.pkl')\n",
    "read = pd.read_pickle('../Pickle/read.pkl')\n",
    "reviews = pd.read_pickle('../Pickle/reviews.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Pickle/umap_embeddings.pkl', 'rb') as f:\n",
    "    umap_embeddings = pickle.load(f)\n",
    "\n",
    "faiss_index = faiss.read_index('../Pickle/faiss_index.bin')\n",
    "\n",
    "with open('../Pickle/book_id_to_index.pkl', 'rb') as f:\n",
    "    book_id_to_index = pickle.load(f)\n",
    "\n",
    "with open('../Pickle/user_id_to_index_gat.pkl', 'rb') as f:\n",
    "    user_id_to_index_gat = pickle.load(f)\n",
    "\n",
    "with open('../Pickle/book_id_to_index_gat.pkl', 'rb') as f:\n",
    "    book_id_to_index_gat = pickle.load(f)\n",
    "\n",
    "with open('../Pickle/gat_embeddings.pkl', 'rb') as f:\n",
    "    all_embeddings = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id_to_index_gat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_id_to_index_gat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read = read[read['is_read']== 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_book_ids = set(books['book_id'])\n",
    "interactions = interactions[interactions['book_id'].isin(valid_book_ids)]\n",
    "read = read[read['book_id'].isin(valid_book_ids)]\n",
    "reviews = reviews[reviews['book_id'].isin(valid_book_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from Gatv2Conv import GATModel  # Import the model class from the other file\n",
    "\n",
    "# Define the model architecture\n",
    "model = GATModel(\n",
    "    in_channels=32,  # Input features per node\n",
    "    hidden_channels=25,\n",
    "    out_channels=1,\n",
    "    num_heads=25,\n",
    "    edge_feature_dim=386  # Correct edge feature dimension\n",
    ")\n",
    "\n",
    "# Load the saved model weights\n",
    "model.load_state_dict(torch.load('../RecSysJupyter/gat_model.pth'))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = 8193"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_books_read = read[read['user_id'] == user_id ]\n",
    "user_num_books = user_books_read['book_id'].nunique()\n",
    "user_reviews = interactions[interactions['user_id']== user_id]\n",
    "user_num_reviews = user_reviews['book_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_books = interactions['book_id'].unique()\n",
    "unread_books = list(set(all_books) - set(user_books_read))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unread_books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_books_HDBSCAN(book_id, books=books, umap_embeddings=umap_embeddings, top_n=5, book_id_to_index=book_id_to_index):\n",
    "    if book_id not in book_id_to_index:\n",
    "        print(f\"Warning: {book_id} is not in book_id_to_index.\")  # Print missing book_id\n",
    "        return (\"not in index\")  # Return empty if book_id is not in book_id_to_index\n",
    "\n",
    "    book_idx = book_id_to_index[book_id]\n",
    "    input_book_title = books.loc[books['book_id'] == book_id, 'title'].values[0]\n",
    "\n",
    "    # Search for nearest neighbors using FAISS\n",
    "    distances, indices = faiss_index.search(np.array([umap_embeddings[book_idx]]), top_n + 1)\n",
    "\n",
    "    recommendations = []\n",
    "    for idx, dist in zip(indices[0][1:], distances[0][1:]):  # Exclude the book itself\n",
    "        # Check if the index is within bounds\n",
    "        if idx >= len(books):\n",
    "            print(f\"Warning: Index {idx} is out of bounds for books DataFrame.\")\n",
    "            continue  # Skip if the index is out of bounds\n",
    "\n",
    "        recommended_book = books.iloc[idx]\n",
    "        explanation = f\"Similarity Score: {round(1 / (1 + dist), 3)}\"\n",
    "        recommendations.append({\n",
    "            \"title\": recommended_book[\"title\"],\n",
    "            \"authors\": recommended_book[\"authors\"],\n",
    "            \"cluster\": recommended_book.get(\"cluster\", \"N/A\"),\n",
    "            \"explanation\": explanation\n",
    "        })\n",
    "\n",
    "    return recommendations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_books_NMF(model, interactions, user_id, books_read, books, n_recommendations=5):\n",
    "    \"\"\"Recommend top-N books for a specific user or all users using the trained NMF model.\"\"\"\n",
    "    # Get unique books from the interactions dataset\n",
    "    all_books = interactions['book_id'].unique()\n",
    "    unread_books = list(set(all_books) - set(books_read))\n",
    "\n",
    "    # Predict ratings for unread books\n",
    "    user_predictions = [\n",
    "        (book_id, model.predict(uid=user_id, iid=book_id).est) for book_id in unread_books\n",
    "    ]\n",
    "    \n",
    "    # Sort predictions by estimated rating in descending order\n",
    "    user_predictions.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Get the top-N recommended books and map to title, authors, and rating\n",
    "    top_books = user_predictions[:n_recommendations]\n",
    "    top_books_with_details = []\n",
    "    \n",
    "    for book_id, rating in top_books:\n",
    "        # Lookup the title and authors of the book using the books DataFrame\n",
    "        book_info = books.loc[books['book_id'] == book_id, ['title', 'authors']].values[0]\n",
    "        book_title = book_info[0]\n",
    "        book_authors = book_info[1]\n",
    "        \n",
    "        # Append the book_id, title, authors, and rating to the list\n",
    "        top_books_with_details.append((book_id, book_title, book_authors, rating))\n",
    "        \n",
    "    return {user_id: top_books_with_details}  # Return list of (book_id, title, authors, predicted_rating)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def recommend_books_GAT(user_id, unread_book_ids, all_embeddings, user_id_to_index, book_id_to_index, books_df):\n",
    "    \"\"\"\n",
    "    Predicts ratings for a user against multiple unread books using GAT embeddings.\n",
    "    Returns the top 5 recommended books with titles and denormalised ratings.\n",
    "    \"\"\"\n",
    "    # Map user ID to index\n",
    "    user_index = user_id_to_index.get(user_id, None)\n",
    "    if user_index is None:\n",
    "        raise ValueError(f\"User ID {user_id} not found in index mappings.\")\n",
    "\n",
    "    # Get user embedding\n",
    "    user_embedding = all_embeddings[user_index]\n",
    "\n",
    "    predictions = []  # Store (book_id, title, predicted_rating)\n",
    "\n",
    "    for book_id in unread_book_ids:\n",
    "        book_index = book_id_to_index.get(book_id, None)\n",
    "        if book_index is None:\n",
    "            continue  # Skip books not found in mapping\n",
    "\n",
    "        # Get book embedding\n",
    "        book_embedding = all_embeddings[book_index]\n",
    "\n",
    "        # Compute dot product (raw score)\n",
    "        predicted_rating = np.dot(user_embedding, book_embedding)\n",
    "\n",
    "        # Denormalise using expm1 (inverse of log1p)\n",
    "        predicted_rating = np.expm1(predicted_rating)\n",
    "\n",
    "        # Get book title from books_df\n",
    "        book_title = books_df.loc[books_df['book_id'] == book_id, 'title'].values\n",
    "        book_title = book_title[0] if len(book_title) > 0 else \"Unknown Title\"\n",
    "\n",
    "        # Store (book_id, title, predicted_rating)\n",
    "        predictions.append((book_id, book_title, predicted_rating))\n",
    "\n",
    "    # Sort by predicted rating (descending) and return top 5\n",
    "    top_recommendations = sorted(predictions, key=lambda x: x[2], reverse=True)[:5]\n",
    "\n",
    "    return top_recommendations  # Returns [(book_id, title, predicted_rating), ...]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example User and Book IDs\n",
    "user_id = 8193\n",
    "book_id = 24584\n",
    "\n",
    "\n",
    "top_books = recommend_books_GAT(user_id, unread_books, all_embeddings, user_id_to_index_gat, book_id_to_index_gat, books)\n",
    "\n",
    "print(\"Top 5 recommended books:\")\n",
    "for book_id, title, rating in top_books:\n",
    "    print(f\" {title} (Book ID: {book_id}) - Predicted Rating: {rating:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if user_num_books < 5:\n",
    "    print(f\"User {user_id} has read {user_num_books} books. Using content-based filtering.\")\n",
    "    recommendations = []\n",
    "\n",
    "# For each book the user has read, get recommendations\n",
    "    for book_id in user_books_read:\n",
    "        book_recommendations = recommend_books_HDBSCAN(book_id)\n",
    "        recommendations.extend(book_recommendations)\n",
    "\n",
    "# Remove duplicate recommendations\n",
    "    unique_recommendations = {rec['title']: rec for rec in recommendations}.values()\n",
    "\n",
    "# Convert to a list for easier handling\n",
    "    unique_recommendations = list(unique_recommendations)\n",
    "\n",
    "# Display the recommendations\n",
    "    for rec in unique_recommendations:\n",
    "        print(f\"Title: {rec['title']}\")\n",
    "        print(f\"Authors: {rec['authors']}\")\n",
    "        print(f\"Cluster: {rec['cluster']}\")\n",
    "        print(f\"Explanation: {rec['explanation']}\")\n",
    "        print() \n",
    "        \n",
    "if user_num_books > 5 and user_num_reviews < 5:\n",
    "\n",
    "    print(f\"User {user_id} has read {user_num_books} books. Using collaborative filtering.\")\n",
    "    best_nmf = joblib.load('../Pickle/best_nmf_model.pkl')\n",
    "    book_recommendations = recommend_books_NMF(best_nmf, interactions, user_id, user_books_read , books)\n",
    "    user_predictions = book_recommendations.get(user_id, [])\n",
    "    print(user_predictions)\n",
    "    fifth_rec = user_predictions[3][0]  # book_id of the 5th recommendation\n",
    "     # Feed it into the get_recommendation_by_cluster function to get 5 new books\n",
    "    new_recommendations = recommend_books_HDBSCAN(fifth_rec)\n",
    "        # Take the 1st book from the new recommendations\n",
    "    new_first_rec = new_recommendations[0]\n",
    "        \n",
    "        # Replace the original 5th recommendation with the new first recommendation\n",
    "    user_predictions[4] = (new_first_rec, user_predictions[4][1])  # Keep the original rating\n",
    "        \n",
    "        # Return the updated recommendations for the user\n",
    "    book_recommendations[user_id] = user_predictions[:5]\n",
    "    print(user_predictions)\n",
    "\n",
    "if user_num_books > 5 and user_num_reviews > 5:\n",
    "    print(\"using nmf and gat2vconv\")\n",
    "    print(f\"User {user_id} has read {user_num_books} books. Using collaborative filtering.\")\n",
    "    best_nmf = joblib.load('../Pickle/best_nmf_model.pkl')\n",
    "    book_recommendations = recommend_books_NMF(best_nmf, interactions, user_id, user_books_read , books)\n",
    "    user_predictions = book_recommendations.get(user_id, [])\n",
    "    #call recommend_gat function and return boooks\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 8193 has more than 5 books and reviews. Using hybrid filtering (NMF + GAT).\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import faiss\n",
    "import numpy as np\n",
    "import joblib\n",
    "from torch_geometric.nn import GATv2Conv\n",
    "import torch\n",
    "\n",
    "# Load the necessary data\n",
    "def load_data():\n",
    "    books_list = []\n",
    "    with open('../Pickle/books.pkl', 'rb') as file:\n",
    "        while True:\n",
    "            try:\n",
    "                chunk = pickle.load(file)\n",
    "                books_list.append(chunk)\n",
    "            except EOFError:\n",
    "                break\n",
    "    books = pd.concat(books_list, ignore_index=True).drop_duplicates(subset='title', keep='first')\n",
    "\n",
    "    interactions = pd.read_pickle('../Pickle/interactions.pkl')\n",
    "    read = pd.read_pickle('../Pickle/read.pkl')\n",
    "    reviews = pd.read_pickle('../Pickle/reviews.pkl')\n",
    "    with open('../Pickle/umap_embeddings.pkl', 'rb') as f:\n",
    "        umap_embeddings = pickle.load(f)\n",
    "    faiss_index = faiss.read_index('../Pickle/faiss_index.bin')\n",
    "\n",
    "    with open('../Pickle/book_id_to_index.pkl', 'rb') as f:\n",
    "        book_id_to_index = pickle.load(f)\n",
    "    with open('../Pickle/user_id_to_index_gat.pkl', 'rb') as f:\n",
    "        user_id_to_index_gat = pickle.load(f)\n",
    "    with open('../Pickle/book_id_to_index_gat.pkl', 'rb') as f:\n",
    "        book_id_to_index_gat = pickle.load(f)\n",
    "    with open('../Pickle/gat_embeddings.pkl', 'rb') as f:\n",
    "        all_embeddings = pickle.load(f)\n",
    "\n",
    "    # Filter read and interactions for valid books\n",
    "    read = read[read['is_read'] == 1]\n",
    "    valid_book_ids = set(books['book_id'])\n",
    "    interactions = interactions[interactions['book_id'].isin(valid_book_ids)]\n",
    "    read = read[read['book_id'].isin(valid_book_ids)]\n",
    "    reviews = reviews[reviews['book_id'].isin(valid_book_ids)]\n",
    "\n",
    "    return books, interactions, read, reviews, umap_embeddings, faiss_index, book_id_to_index, user_id_to_index_gat, book_id_to_index_gat, all_embeddings\n",
    "\n",
    "# Load GAT model\n",
    "def load_gat_model():\n",
    "    from Gatv2Conv import GATModel\n",
    "    model = GATModel(\n",
    "        in_channels=32,  # Input features per node\n",
    "        hidden_channels=25,\n",
    "        out_channels=1,\n",
    "        num_heads=25,\n",
    "        edge_feature_dim=386  # Edge feature dimension\n",
    "    )\n",
    "    model.load_state_dict(torch.load('../RecSysJupyter/gat_model.pth'))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "# Recommendation function for HDBSCAN (Content-based)\n",
    "def recommend_books_HDBSCAN(book_id, books, umap_embeddings, faiss_index, book_id_to_index, top_n=5):\n",
    "    if book_id not in book_id_to_index:\n",
    "        return []\n",
    "\n",
    "    book_idx = book_id_to_index[book_id]\n",
    "    distances, indices = faiss_index.search(np.array([umap_embeddings[book_idx]]), top_n + 1)\n",
    "    recommendations = []\n",
    "\n",
    "    for idx, dist in zip(indices[0][1:], distances[0][1:]):  # Exclude the book itself\n",
    "        if idx >= len(books):\n",
    "            continue  # Skip out-of-bounds indices\n",
    "\n",
    "        recommended_book = books.iloc[idx]\n",
    "        explanation = f\"Similarity Score: {round(1 / (1 + dist), 3)}\"\n",
    "        recommendations.append({\n",
    "            \"book_id\": recommended_book[\"book_id\"],\n",
    "            \"title\": recommended_book[\"title\"],\n",
    "            \"authors\": ', '.join(recommended_book[\"authors\"]) if isinstance(recommended_book[\"authors\"], list) else recommended_book[\"authors\"],\n",
    "            \"predicted_rating\": \"N/A\",\n",
    "            \"explanation\": explanation\n",
    "        })\n",
    "\n",
    "    return recommendations\n",
    "\n",
    "# Recommendation function for NMF (Collaborative filtering)\n",
    "def recommend_books_NMF(nmf_model, interactions, user_id, books_read, books, n_recommendations=5):\n",
    "    all_books = interactions['book_id'].unique()\n",
    "    unread_books = list(set(all_books) - set(books_read))\n",
    "\n",
    "    # Predict ratings for unread books\n",
    "    user_predictions = [\n",
    "        (book_id, nmf_model.predict(uid=user_id, iid=book_id).est) for book_id in unread_books\n",
    "    ]\n",
    "\n",
    "    user_predictions.sort(key=lambda x: x[1], reverse=True)\n",
    "    top_books = user_predictions[:n_recommendations]\n",
    "\n",
    "    recommendations = []\n",
    "    for book_id, rating in top_books:\n",
    "        book_info = books.loc[books['book_id'] == book_id, ['title', 'authors']].values[0]\n",
    "        recommendations.append({\n",
    "            \"book_id\": book_id,\n",
    "            \"title\": book_info[0],\n",
    "            \"authors\": ', '.join(book_info[1]) if isinstance(book_info[1], list) else book_info[1],\n",
    "            \"predicted_rating\": rating,\n",
    "            \"explanation\": \"N/A\"  # Add an explanation if needed\n",
    "        })\n",
    "\n",
    "    return recommendations\n",
    "\n",
    "# Recommendation function for GAT (Hybrid filtering)\n",
    "def recommend_books_GAT(user_id, unread_book_ids, all_embeddings, user_id_to_index, book_id_to_index, books_df, top_n=5):\n",
    "    user_index = user_id_to_index.get(user_id)\n",
    "    if user_index is None:\n",
    "        raise ValueError(f\"User ID {user_id} not found in index mappings.\")\n",
    "\n",
    "    user_embedding = all_embeddings[user_index]\n",
    "    predictions = []\n",
    "\n",
    "    for book_id in unread_book_ids:\n",
    "        book_index = book_id_to_index.get(book_id)\n",
    "        if book_index is None:\n",
    "            continue\n",
    "\n",
    "        book_embedding = all_embeddings[book_index]\n",
    "        predicted_rating = np.dot(user_embedding, book_embedding)\n",
    "        predicted_rating = np.expm1(predicted_rating)  # Denormalise\n",
    "\n",
    "        book_title = books_df.loc[books_df['book_id'] == book_id, 'title'].values[0]\n",
    "        predictions.append({\n",
    "            \"book_id\": book_id,\n",
    "            \"title\": book_title,\n",
    "            \"authors\": ', '.join(books_df.loc[books_df['book_id'] == book_id, 'authors'].values[0]) if isinstance(books_df.loc[books_df['book_id'] == book_id, 'authors'].values[0], list) else books_df.loc[books_df['book_id'] == book_id, 'authors'].values[0],\n",
    "            \"predicted_rating\": predicted_rating,\n",
    "            \"explanation\": \"N/A\"  # Add an explanation if needed\n",
    "        })\n",
    "\n",
    "    top_recommendations = sorted(predictions, key=lambda x: x[\"predicted_rating\"], reverse=True)[:top_n]\n",
    "    return top_recommendations\n",
    "\n",
    "\n",
    "\n",
    "# Main recommendation logic\n",
    "def recommend_for_user(user_id, books, interactions, read, umap_embeddings, faiss_index, book_id_to_index, user_id_to_index_gat, book_id_to_index_gat, all_embeddings):\n",
    "    user_books_read = read[read['user_id'] == user_id]\n",
    "    user_num_books = user_books_read['book_id'].nunique()\n",
    "    user_reviews = reviews[reviews['user_id'] == user_id]  # Assuming 'user_id' is in your interactions\n",
    "    user_num_reviews = user_reviews.shape[0]  # Number of reviews for the user\n",
    "\n",
    "    all_books = interactions['book_id'].unique()\n",
    "    unread_books = list(set(all_books) - set(user_books_read['book_id']))\n",
    "\n",
    "    if user_num_books < 5:\n",
    "        print(f\"User {user_id} has read {user_num_books} books. Using content-based filtering.\")\n",
    "        recommendations = []\n",
    "        for book_id in user_books_read['book_id']:\n",
    "            book_recommendations = recommend_books_HDBSCAN(book_id, books, umap_embeddings, faiss_index, book_id_to_index)\n",
    "            recommendations.extend(book_recommendations)\n",
    "\n",
    "        unique_recommendations = {rec['title']: rec for rec in recommendations}.values()\n",
    "        return list(unique_recommendations)\n",
    "\n",
    "    if user_num_books > 5:\n",
    "        best_nmf = joblib.load('../Pickle/best_nmf_model.pkl')\n",
    "\n",
    "        # Collaborative filtering if reviews < 5\n",
    "        if user_num_reviews < 5:\n",
    "            print(f\"User {user_id} has fewer reviews. Using collaborative filtering (NMF).\")\n",
    "            book_recommendations = recommend_books_NMF(best_nmf, interactions, user_id, user_books_read['book_id'], books)\n",
    "            return book_recommendations\n",
    "\n",
    "        # Hybrid recommendation (NMF + GAT)\n",
    "        print(f\"User {user_id} has more than 5 books and reviews. Using hybrid filtering (NMF + GAT).\")\n",
    "        book_recommendations = recommend_books_NMF(best_nmf, interactions, user_id, user_books_read['book_id'], books)\n",
    "        gat_recommendations = recommend_books_GAT(user_id, unread_books, all_embeddings, user_id_to_index_gat, book_id_to_index_gat, books)\n",
    "\n",
    "        recommendations = book_recommendations + gat_recommendations\n",
    "        return recommendations\n",
    "\n",
    "# Example usage\n",
    "books, interactions, read, reviews, umap_embeddings, faiss_index, book_id_to_index, user_id_to_index_gat, book_id_to_index_gat, all_embeddings = load_data()\n",
    "user_id = 8193\n",
    "recommendations = recommend_for_user(user_id, books, interactions, read, umap_embeddings, faiss_index, book_id_to_index, user_id_to_index_gat, book_id_to_index_gat, all_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'book_id': 131072,\n",
       "  'title': 'An Introduction to Ancient Egyptian Literature',\n",
       "  'authors': 'E.A. Wallis Budge',\n",
       "  'predicted_rating': 3.0476281670720264,\n",
       "  'explanation': 'N/A'},\n",
       " {'book_id': 262151,\n",
       "  'title': 'Socrates In Love',\n",
       "  'authors': 'Kyoichi Katayama',\n",
       "  'predicted_rating': 3.0476281670720264,\n",
       "  'explanation': 'N/A'},\n",
       " {'book_id': 131081,\n",
       "  'title': 'Dark Horse',\n",
       "  'authors': 'Fletcher Knebel',\n",
       "  'predicted_rating': 3.0476281670720264,\n",
       "  'explanation': 'N/A'},\n",
       " {'book_id': 131088,\n",
       "  'title': 'The Cold Blue Blood (Berger and Mitry, #1)',\n",
       "  'authors': 'David Handler',\n",
       "  'predicted_rating': 3.0476281670720264,\n",
       "  'explanation': 'N/A'},\n",
       " {'book_id': 65557,\n",
       "  'title': \"The Bride's Necklace (Necklace Trilogy, #1)\",\n",
       "  'authors': 'Kat Martin',\n",
       "  'predicted_rating': 3.0476281670720264,\n",
       "  'explanation': 'N/A'},\n",
       " {'book_id': 33837,\n",
       "  'title': 'When Night Falls',\n",
       "  'authors': 'Linda  Anderson',\n",
       "  'predicted_rating': 3.6996765,\n",
       "  'explanation': 'N/A'},\n",
       " {'book_id': 42716,\n",
       "  'title': 'Not Just For Christmas',\n",
       "  'authors': 'Roddy Doyle',\n",
       "  'predicted_rating': 3.6996765,\n",
       "  'explanation': 'N/A'},\n",
       " {'book_id': 60202,\n",
       "  'title': 'At Home with the Marquis de Sade: A Life',\n",
       "  'authors': 'Francine du Plessix Gray',\n",
       "  'predicted_rating': 3.6996765,\n",
       "  'explanation': 'N/A'},\n",
       " {'book_id': 25717,\n",
       "  'title': 'Good Harbor',\n",
       "  'authors': 'Anita Diamant',\n",
       "  'predicted_rating': 3.6370769,\n",
       "  'explanation': 'N/A'},\n",
       " {'book_id': 7196,\n",
       "  'title': 'The Balance Thing',\n",
       "  'authors': 'Margaret Dumas',\n",
       "  'predicted_rating': 3.6365337,\n",
       "  'explanation': 'N/A'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book ID: 131072\n",
      "Title: An Introduction to Ancient Egyptian Literature\n",
      "Authors: E.A. Wallis Budge\n",
      "Predicted Rating: 3.0476\n",
      "----------------------------------------\n",
      "Book ID: 262151\n",
      "Title: Socrates In Love\n",
      "Authors: Kyoichi Katayama\n",
      "Predicted Rating: 3.0476\n",
      "----------------------------------------\n",
      "Book ID: 131081\n",
      "Title: Dark Horse\n",
      "Authors: Fletcher Knebel\n",
      "Predicted Rating: 3.0476\n",
      "----------------------------------------\n",
      "Book ID: 131088\n",
      "Title: The Cold Blue Blood (Berger and Mitry, #1)\n",
      "Authors: David Handler\n",
      "Predicted Rating: 3.0476\n",
      "----------------------------------------\n",
      "Book ID: 65557\n",
      "Title: The Bride's Necklace (Necklace Trilogy, #1)\n",
      "Authors: Kat Martin\n",
      "Predicted Rating: 3.0476\n",
      "----------------------------------------\n",
      "Book ID: 33837\n",
      "Title: When Night Falls\n",
      "Authors: Linda  Anderson\n",
      "Predicted Rating: 3.6997\n",
      "----------------------------------------\n",
      "Book ID: 42716\n",
      "Title: Not Just For Christmas\n",
      "Authors: Roddy Doyle\n",
      "Predicted Rating: 3.6997\n",
      "----------------------------------------\n",
      "Book ID: 60202\n",
      "Title: At Home with the Marquis de Sade: A Life\n",
      "Authors: Francine du Plessix Gray\n",
      "Predicted Rating: 3.6997\n",
      "----------------------------------------\n",
      "Book ID: 25717\n",
      "Title: Good Harbor\n",
      "Authors: Anita Diamant\n",
      "Predicted Rating: 3.6371\n",
      "----------------------------------------\n",
      "Book ID: 7196\n",
      "Title: The Balance Thing\n",
      "Authors: Margaret Dumas\n",
      "Predicted Rating: 3.6365\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for rec in recommendations:\n",
    "    print(f\"Book ID: {rec['book_id']}\")\n",
    "    print(f\"Title: {rec['title']}\")\n",
    "    \n",
    "    # Check if 'authors' is a list or a single string\n",
    "    print(f\"Authors: {rec['authors']}\")\n",
    "    print(f\"Predicted Rating: {rec['predicted_rating']:.4f}\")\n",
    "    print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "goodreads",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
