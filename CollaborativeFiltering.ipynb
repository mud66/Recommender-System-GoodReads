{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "read = pd.read_pickle('Pickle/read.pkl')\n",
    "books = pd.read_pickle('Pickle/books.pkl')\n",
    "reviews = pd.read_pickle('Pickle/reviews.pkl')\n",
    "interactions = pd.read_pickle('Pickle/interactions.pkl')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Group by user_id and count ratings\n",
    "user_rating_counts = interactions.groupby('user_id').size().reset_index(name='rating_count')\n",
    "\n",
    "# Step 2: Filter users with less than 3 ratings\n",
    "users_with_enough_ratings = user_rating_counts[user_rating_counts['rating_count'] >= 5]['user_id']\n",
    "\n",
    "# Step 3: Filter the interactions DataFrame to include only these users\n",
    "interactions = interactions[interactions['user_id'].isin(users_with_enough_ratings)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions = interactions[interactions['is_read']== True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = reviews.dropna(subset=['review_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique user IDs from both DataFrames\n",
    "interaction_user_ids = set(interactions['user_id'].unique())\n",
    "review_user_ids = set(reviews['user_id'].unique())\n",
    "read_user_ids = set(read['user_id'].unique())\n",
    "\n",
    "\n",
    "# Find the common user IDs\n",
    "common = interaction_user_ids.intersection(review_user_ids)\n",
    "common_user_ids = common.intersection(read_user_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1368"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(common_user_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter interactions DataFrame\n",
    "interactions = interactions[interactions['user_id'].isin(common_user_ids)]\n",
    "# Filter reviews DataFrame\n",
    "reviews = reviews[reviews['user_id'].isin(common_user_ids)]\n",
    "read = read[read['user_id'].isin(common_user_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71108"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maddy\\anaconda3\\envs\\goodreads\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "100%|██████████| 71108/71108 [14:08<00:00, 83.81it/s]  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "def save_embeddings_incrementally(reviews_df, model, interval=100):\n",
    "    embeddings_file = 'Pickle/review_embeddings.pkl'\n",
    "    \n",
    "    if os.path.exists(embeddings_file):\n",
    "        embeddings_df = pd.read_pickle(embeddings_file)\n",
    "    else:\n",
    "        embeddings_df = pd.DataFrame(columns=['index', 'embeddings'])\n",
    "    \n",
    "    reviews_df = reviews_df.dropna(subset=['review_text']).reset_index(drop=True)\n",
    "\n",
    "    for i in tqdm(range(len(reviews_df))):\n",
    "        if i in embeddings_df['index'].values:\n",
    "            continue  # Skip if already processed\n",
    "        \n",
    "        embedding = model.encode(reviews_df.loc[i, 'review_text'])\n",
    "        new_row = pd.DataFrame({'index': [i], 'embeddings': [embedding]})\n",
    "        embeddings_df = pd.concat([embeddings_df, new_row], ignore_index=True)\n",
    "        \n",
    "        if i % interval == 0:\n",
    "            embeddings_df.to_pickle(embeddings_file)\n",
    "    \n",
    "    # Save the final version\n",
    "    embeddings_df.to_pickle(embeddings_file)\n",
    "\n",
    "# Save embeddings incrementally\n",
    "save_embeddings_incrementally(reviews, model, interval=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71108/71108 [04:48<00:00, 246.68it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load the incremental embeddings\n",
    "embeddings_df = pd.read_pickle('Pickle/review_embeddings.pkl')\n",
    "\n",
    "# Ensure the reviews DataFrame has a proper index\n",
    "reviews.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Initialize the embeddings column in reviews DataFrame\n",
    "reviews['embeddings'] = None\n",
    "\n",
    "# Merge embeddings back into the reviews DataFrame\n",
    "for i in tqdm(range(len(reviews))):\n",
    "    if i in embeddings_df['index'].values:\n",
    "        embedding = embeddings_df.loc[embeddings_df['index'] == i, 'embeddings'].values[0]\n",
    "        reviews.at[i, 'embeddings'] = embedding\n",
    "\n",
    "# Ensure all embeddings are numpy arrays\n",
    "def convert_to_array(x):\n",
    "    if isinstance(x, list):\n",
    "        return np.array(x)\n",
    "    return x\n",
    "\n",
    "reviews['embeddings'] = reviews['embeddings'].apply(convert_to_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_weighted_embeddings(reviews_df, base_weight=0.1):\n",
    "    # Normalize n_votes and n_comments\n",
    "    reviews_df.loc[:, 'n_votes_normalized'] = reviews_df['n_votes'] / reviews_df['n_votes'].max()\n",
    "    reviews_df.loc[:, 'n_comments_normalized'] = reviews_df['n_comments'] / reviews_df['n_comments'].max()\n",
    "\n",
    "    # Calculate weights with a base weight\n",
    "    reviews_df.loc[:, 'weight'] = base_weight + reviews_df['n_votes_normalized'] + reviews_df['n_comments_normalized']\n",
    "\n",
    "    # Apply weights to embeddings\n",
    "    reviews_df.loc[:, 'weighted_embeddings'] = reviews_df.apply(lambda row: row['embeddings'] * row['weight'], axis=1)\n",
    "    return reviews_df\n",
    "\n",
    "# Apply the function\n",
    "reviews = calculate_weighted_embeddings(reviews)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate weighted embeddings by user\n",
    "user_embeddings = reviews.groupby('user_id')['weighted_embeddings'].apply(lambda x: np.mean(np.vstack(x.dropna()), axis=0)).reset_index()\n",
    "\n",
    "# Calculate User-User Similarity\n",
    "def calculate_user_similarity(user_embeddings):\n",
    "    user_features = np.vstack(user_embeddings['weighted_embeddings'])\n",
    "    user_similarity = cosine_similarity(user_features, user_features)\n",
    "    return user_similarity\n",
    "\n",
    "user_similarity = calculate_user_similarity(user_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "books['average_rating'] = books['average_rating'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_books(user_id, num_recommendations=5):\n",
    "    # Check if user_id is in the user_embeddings dataframe\n",
    "    if user_id not in user_embeddings['user_id'].values:\n",
    "        print(\"User not found in user embeddings.\")\n",
    "        return pd.DataFrame(columns=['book_id', 'title'])\n",
    "\n",
    "    # Identify similar users\n",
    "    user_index = user_embeddings[user_embeddings['user_id'] == user_id].index[0]\n",
    "    similar_user_indices = user_similarity[user_index].argsort()[-(num_recommendations+10):-1][::-1]  # Consider more similar users\n",
    "    similar_user_ids = user_embeddings.iloc[similar_user_indices]['user_id'].values\n",
    "\n",
    "    # Ensure similar_user_ids are in the read DataFrame\n",
    "    valid_similar_user_ids = [uid for uid in similar_user_ids if uid in read['user_id'].unique()]\n",
    "\n",
    "    if len(valid_similar_user_ids) == 0:\n",
    "        print(\"No valid similar users found.\")\n",
    "        return pd.DataFrame(columns=['book_id', 'title'])\n",
    "\n",
    "    # Get books read by similar users\n",
    "    similar_users_books = read[read['user_id'].isin(valid_similar_user_ids) & (read['is_read'] == 1)]['book_id'].unique()\n",
    "\n",
    "    # Get books the user has read\n",
    "    user_books = read[(read['user_id'] == user_id) & (read['is_read'] == 1)]['book_id'].unique()\n",
    "\n",
    "    # Filter out books already read by the user\n",
    "    recommended_books = [book_id for book_id in similar_users_books if book_id not in user_books]\n",
    "\n",
    "    # Filter books with an average rating of 3 or above\n",
    "    recommended_books = books[(books['book_id'].isin(recommended_books)) & (books['average_rating'] >= 3)]\n",
    "\n",
    "    if len(recommended_books) == 0:\n",
    "        print(\"No new books to recommend.\")\n",
    "        return pd.DataFrame(columns=['book_id', 'title'])\n",
    "\n",
    "    # Get details of the recommended books\n",
    "    recommended_books_df = recommended_books.head(num_recommendations)\n",
    "    return recommended_books_df[['book_id', 'title']]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "goodreads",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
