{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "# Load data\n",
    "read = pd.read_feather('Feather/read.feather')\n",
    "books = pd.read_feather('Feather/books.feather')    \n",
    "reviews = pd.read_feather('Feather/reviews.feather')\n",
    "interactions = pd.read_feather('Feather/interactions.feather')\n",
    "interactions = interactions[interactions['is_read'] == True]\n",
    "\n",
    "# Clean reviews\n",
    "reviews = reviews.dropna(subset=['review_text', 'rating'])\n",
    "user_review_counts = reviews.groupby('user_id').size()\n",
    "users_with_more_than_3_reviews = user_review_counts[user_review_counts > 3].index\n",
    "valid_reviews = reviews[reviews['user_id'].isin(users_with_more_than_3_reviews)].head(1000)\n",
    "\n",
    "# Train-test split\n",
    "train_interactions, test_interactions = train_test_split(interactions, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize Sentence Transformer model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Calculate text embeddings for reviews\n",
    "valid_reviews['review_embeddings'] = valid_reviews['review_text'].progress_apply(lambda x: model.encode(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine review embeddings by user\n",
    "user_embeddings = valid_reviews.groupby('user_id')['review_embeddings'].apply(lambda x: np.mean(np.vstack(x), axis=0)).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize ratings\n",
    "train_interactions['rating_normalized'] = (train_interactions['rating'] - train_interactions['rating'].min()) / (train_interactions['rating'].max() - train_interactions['rating'].min())\n",
    "user_ratings = train_interactions.groupby('user_id')['rating_normalized'].mean().reset_index()\n",
    "\n",
    "# Merge features\n",
    "combined_features = pd.merge(user_embeddings, user_ratings, on='user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate User-User Similarity\n",
    "user_features = combined_features['review_embeddings'].apply(pd.Series).values\n",
    "user_similarity = cosine_similarity(user_features, user_features)\n",
    "books = books.drop_duplicates(subset='book_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to recommend books based on user similarity\n",
    "def recommend_books(user_id, user_similarity, interactions_df, books_df, combined_features, num_recommendations=5):\n",
    "    if user_id not in combined_features['user_id'].values:\n",
    "        return pd.DataFrame(columns=['book_id', 'title', 'authors'])\n",
    "\n",
    "    # Identify similar users\n",
    "    user_index = combined_features[combined_features['user_id'] == user_id].index[0]\n",
    "    similar_user_ids = combined_features['user_id'].iloc[user_similarity[user_index].argsort()[-num_recommendations-1:-1][::-1]].values\n",
    "\n",
    "    # Get books read by similar users\n",
    "    similar_users_books = interactions_df[interactions_df['user_id'].isin(similar_user_ids)]['book_id'].unique()\n",
    "\n",
    "    # Exclude books already read by the current user\n",
    "    user_books = interactions_df[interactions_df['user_id'] == user_id]['book_id'].values\n",
    "    recommended_books = [book for book in similar_users_books if book not in user_books]\n",
    "\n",
    "    return books_df[books_df['book_id'].isin(recommended_books)][['book_id']].head(num_recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# RMSE function\n",
    "def calculate_rmse(predictions, targets):\n",
    "    return np.sqrt(mean_squared_error(targets, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision@k function\n",
    "def precision_at_k(recommended_books, relevant_books, k):\n",
    "    recommended_books = recommended_books[:k]\n",
    "    relevant_set = set(relevant_books)\n",
    "    recommended_set = set(recommended_books)\n",
    "    return len(recommended_set & relevant_set) / k\n",
    "\n",
    "# Recall@k function\n",
    "def recall_at_k(recommended_books, relevant_books, k):\n",
    "    relevant_set = set(relevant_books)\n",
    "    if len(relevant_set) == 0:\n",
    "        return 0\n",
    "    recommended_set = set(recommended_books[:k])\n",
    "    return len(recommended_set & relevant_set) / len(relevant_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation function\n",
    "def evaluate_model(test_df, user_similarity, interactions_df, books_df, combined_features, k=5):\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    actuals = []\n",
    "    predictions = []\n",
    "\n",
    "    for index, row in test_df.iterrows():\n",
    "        user_id = row['user_id']\n",
    "        actual_rating = row['rating']\n",
    "        recommended_books = recommend_books(user_id, user_similarity, interactions_df, books_df, combined_features, k)\n",
    "        if len(recommended_books) > 0:\n",
    "            predicted_rating = combined_features[combined_features['user_id'] == user_id]['rating_normalized'].values[0]\n",
    "            predictions.append(predicted_rating)\n",
    "            actuals.append(actual_rating)\n",
    "\n",
    "            # Precision@k and Recall@k\n",
    "            user_relevant_books = interactions_df[(interactions_df['user_id'] == user_id) & (interactions_df['rating'] >= 3)]['book_id'].values\n",
    "            precisions.append(precision_at_k(recommended_books['book_id'].values, user_relevant_books, k))\n",
    "            recalls.append(recall_at_k(recommended_books['book_id'].values, user_relevant_books, k))\n",
    "\n",
    "    mse = mean_squared_error(actuals, predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mean_precision = np.mean(precisions)\n",
    "    mean_recall = np.mean(recalls)\n",
    "\n",
    "    return rmse, mean_precision, mean_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example usage:\n",
    "k = 5\n",
    "rmse, mean_precision, mean_recall = evaluate_model(test_interactions, user_similarity, train_interactions, books, combined_features, k)\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"Precision@{k}: {mean_precision}\")\n",
    "print(f\"Recall@{k}: {mean_recall}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "goodreads",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
