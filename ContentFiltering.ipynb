{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maddy\\anaconda3\\envs\\goodreads\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import PCA, IncrementalPCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import normalize\n",
    "from tqdm import tqdm\n",
    "import dask.array as da\n",
    "from dask_ml.decomposition import PCA\n",
    "import faiss\n",
    "import os\n",
    "tqdm.pandas()\n",
    "pd.options.display.max_colwidth = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "read = pd.read_pickle('Pickle/read.pkl')\n",
    "books = pd.read_pickle('Pickle/books.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "books = books.sample(50000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to drop empty rows\n",
    "def drop_empty_rows(df, column_name):\n",
    "    df_cleaned = df.dropna(subset=[column_name])\n",
    "    return df_cleaned\n",
    "\n",
    "books = drop_empty_rows(books, 'description')\n",
    "books = books.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify valid book IDs present in both dataframes\n",
    "valid_book_ids = set(read['book_id']).intersection(set(books['book_id']))\n",
    "\n",
    "# Filter the books dataframe\n",
    "books_filtered = books[books['book_id'].isin(valid_book_ids)]\n",
    "\n",
    "# Filter the read dataframe\n",
    "read_filtered = read[read['book_id'].isin(valid_book_ids)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "books['combined_features'] = books.apply(\n",
    "    lambda row: f\"{row['title']} by {row['authors']}, \" +\n",
    "                f\"Description: {row['description']}, \" +\n",
    "                f\"Shelves: {row['expanded_shelves']}\",\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "books = books.reset_index(drop=True)\n",
    "read = read.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maddy\\anaconda3\\envs\\goodreads\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "only have to compute an embedding once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [01:22<00:00, 608.73it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Function to periodically save the embeddings to a separate file\n",
    "def save_embeddings_incrementally(books_df, model, interval=100):\n",
    "    embeddings_file = 'Pickle/embeddings.pkl'\n",
    "    \n",
    "    if os.path.exists(embeddings_file):\n",
    "        embeddings_df = pd.read_pickle(embeddings_file)\n",
    "    else:\n",
    "        embeddings_df = pd.DataFrame(columns=['index', 'embeddings'])\n",
    "    \n",
    "    for i in tqdm(range(len(books_df))):\n",
    "        if i in embeddings_df['index'].values:\n",
    "            continue  # Skip if already processed\n",
    "        \n",
    "        embedding = model.encode(books_df.at[i, 'combined_features'])\n",
    "        new_row = pd.DataFrame({'index': [i], 'embeddings': [embedding]})\n",
    "        embeddings_df = pd.concat([embeddings_df, new_row], ignore_index=True)\n",
    "        \n",
    "        if i % interval == 0:\n",
    "            embeddings_df.to_pickle(embeddings_file)\n",
    "    \n",
    "    # Save the final version\n",
    "    embeddings_df.to_pickle(embeddings_file)\n",
    "\n",
    "# Save embeddings incrementally\n",
    "save_embeddings_incrementally(books, model, interval=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [05:59<00:00, 139.10it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load the incremental embeddings\n",
    "embeddings_df = pd.read_pickle('Pickle/embeddings.pkl')\n",
    "\n",
    "# Merge embeddings back into the original DataFrame\n",
    "books['embeddings'] = None\n",
    "for i in tqdm(range(len(books))):\n",
    "    if i in embeddings_df['index'].values:\n",
    "        books.at[i, 'embeddings'] = embeddings_df[embeddings_df['index'] == i]['embeddings'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.vstack(books['embeddings'].values)\n",
    "embedding_matrix_dask = da.from_array(embedding_matrix, chunks=(1000, 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce dimensionality\n",
    "pca = PCA(n_components=50)\n",
    "reduced_embeddings = pca.fit_transform(embedding_matrix_dask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_embeddings = reduced_embeddings.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_embeddings = normalize(reduced_embeddings, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = faiss.IndexFlatIP(normalized_embeddings.shape[1])\n",
    "index.add(normalized_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim = cosine_similarity(normalized_embeddings, normalized_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_books, test_books = train_test_split(books, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embedding_matrix = embedding_matrix[train_books.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embedding_matrix = embedding_matrix[test_books.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim_train = cosine_similarity(train_embedding_matrix, train_embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim_test = cosine_similarity(test_embedding_matrix, test_embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get recommendations for a given book_id based on the training set\n",
    "def get_recommendations(book_id, train_books_df, train_cosine_sim_matrix, top_n=5):\n",
    "    if book_id not in train_books_df['book_id'].values:\n",
    "        print(f\"Book ID {book_id} not found in the training books dataframe.\")\n",
    "        return pd.DataFrame(columns=['title', 'authors', 'book_id'])\n",
    "\n",
    "    book_idx = train_books_df[train_books_df['book_id'] == book_id].index[0]\n",
    "    sim_scores = list(enumerate(train_cosine_sim_matrix[book_idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    top_book_ids = [train_books_df['book_id'].iloc[i[0]] for i in sim_scores[1:top_n+1]]\n",
    "    top_books = train_books_df[train_books_df['book_id'].isin(top_book_ids)]\n",
    "\n",
    "    return top_books[['title', 'authors', 'book_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           57080\n",
       "1        35905367\n",
       "2        21798963\n",
       "3        12337584\n",
       "4          531064\n",
       "           ...   \n",
       "49995    29430435\n",
       "49996      937779\n",
       "49997      767765\n",
       "49998      406581\n",
       "49999    29858198\n",
       "Name: book_id, Length: 50000, dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books['book_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>book_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23801</th>\n",
       "      <td>Child's Mind: Mindfulness Practices to Help Our Children Be More Focused, Calm, and Relaxed</td>\n",
       "      <td>[Christopher Willard]</td>\n",
       "      <td>8932852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32678</th>\n",
       "      <td>America's War for the Greater Middle East</td>\n",
       "      <td>[Andrew J. Bacevich]</td>\n",
       "      <td>27994395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36400</th>\n",
       "      <td>Pomegranate Heart</td>\n",
       "      <td>[Miriam Calleja]</td>\n",
       "      <td>25531013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38062</th>\n",
       "      <td>Stone of Farewell (Memory, Sorrow, and Thorn, #2)</td>\n",
       "      <td>[Tad Williams]</td>\n",
       "      <td>1788163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41033</th>\n",
       "      <td>Japan 1941: Countdown to Infamy</td>\n",
       "      <td>[Eri Hotta]</td>\n",
       "      <td>17345183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                             title  \\\n",
       "23801  Child's Mind: Mindfulness Practices to Help Our Children Be More Focused, Calm, and Relaxed   \n",
       "32678                                                    America's War for the Greater Middle East   \n",
       "36400                                                                            Pomegranate Heart   \n",
       "38062                                            Stone of Farewell (Memory, Sorrow, and Thorn, #2)   \n",
       "41033                                                              Japan 1941: Countdown to Infamy   \n",
       "\n",
       "                     authors   book_id  \n",
       "23801  [Christopher Willard]   8932852  \n",
       "32678   [Andrew J. Bacevich]  27994395  \n",
       "36400       [Miriam Calleja]  25531013  \n",
       "38062         [Tad Williams]   1788163  \n",
       "41033            [Eri Hotta]  17345183  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations(231, books, cosine_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>book_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19146</th>\n",
       "      <td>Edge of Dark Water</td>\n",
       "      <td>[Joe R. Lansdale]</td>\n",
       "      <td>11641612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19147</th>\n",
       "      <td>Breathers: A Zombie's Lament</td>\n",
       "      <td>[S.G. Browne]</td>\n",
       "      <td>6568158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37952</th>\n",
       "      <td>Jennifer Crusie Bundle: Welcome to Temptation/ Fast Women/ Faking It</td>\n",
       "      <td>[Jennifer Crusie]</td>\n",
       "      <td>5096123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42438</th>\n",
       "      <td>The Rainbow Dragon: A Narnia Story</td>\n",
       "      <td>[Hiawyn Oram]</td>\n",
       "      <td>34558432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48925</th>\n",
       "      <td>The Way Back To Us</td>\n",
       "      <td>[Kay Langdale]</td>\n",
       "      <td>35382450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                      title  \\\n",
       "19146                                                    Edge of Dark Water   \n",
       "19147                                          Breathers: A Zombie's Lament   \n",
       "37952  Jennifer Crusie Bundle: Welcome to Temptation/ Fast Women/ Faking It   \n",
       "42438                                    The Rainbow Dragon: A Narnia Story   \n",
       "48925                                                    The Way Back To Us   \n",
       "\n",
       "                 authors   book_id  \n",
       "19146  [Joe R. Lansdale]  11641612  \n",
       "19147      [S.G. Browne]   6568158  \n",
       "37952  [Jennifer Crusie]   5096123  \n",
       "42438      [Hiawyn Oram]  34558432  \n",
       "48925     [Kay Langdale]  35382450  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations(421, books, cosine_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "goodreads",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
