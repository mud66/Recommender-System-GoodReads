{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "include authors and title? and maybe only books 3 stars and over?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read = pd.read_feather('Feather/read.feather')\n",
    "books = pd.read_feather('Feather/books.feather')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_empty_rows(df, column_name):\n",
    "   \n",
    "    df_cleaned = df.dropna(subset=[column_name])\n",
    "    return df_cleaned\n",
    "\n",
    "books = drop_empty_rows(books, 'description')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books = books[books['language_code'] == 'eng'].sample(n=1000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books = books.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for all book_ids in read should be the ones in books but ill do that later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "books['embeddings'] = books['combined_text'].progress_apply(lambda x: model.encode(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.vstack(books['embeddings'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=50)\n",
    "embedding_matrix = pca.fit_transform(embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim = cosine_similarity(embedding_matrix, embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books['book_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "given book get top 5 most similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(book_id, books_df, cosine_sim):\n",
    "    # Check if book_id is in books_df\n",
    "    if book_id not in books_df['book_id'].values:\n",
    "        print(f\"Book ID {book_id} not found in the books dataframe.\")\n",
    "        return pd.DataFrame(columns=['title', 'authors'])\n",
    "\n",
    "    # Get the index of the given book_id\n",
    "    book_idx = books_df[books_df['book_id'] == book_id].index[0]\n",
    "\n",
    "    # Calculate similarity scores\n",
    "    sim_scores = list(enumerate(cosine_sim[book_idx]))\n",
    "\n",
    "    # Sort books based on the similarity scores\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Get the book_ids of the top 5 most similar books\n",
    "    top_book_ids = [books_df['book_id'].iloc[i[0]] for i in sim_scores[1:6]]\n",
    "\n",
    "    # Retrieve the details of the top 5 most similar books\n",
    "    top_books = books_df[books_df['book_id'].isin(top_book_ids)]\n",
    "\n",
    "    return top_books[['title']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_id = 17279511\t\n",
    "recommendations = get_recommendations(book_id, books, cosine_sim)\n",
    "print(recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_top_rated_books(books_df, interactions_df):\n",
    "#     top_rated_books = interactions_df.groupby('book_id')['rating'].mean().sort_values(ascending=False).head(5)\n",
    "#     top_rated_books_df = pd.merge(books_df, top_rated_books.reset_index(), on='book_id')\n",
    "#     return top_rated_books_df[['title', 'authors']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "given user get to 5 most similar books based on all books read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_user_recommendations(user_id, read_df, book_df, cosine_sim, num_recommendations=10):\n",
    "#     # Check if user_id exists in read_df\n",
    "#     if user_id not in read_df['user_id'].values:\n",
    "#         print(f\"User {user_id} not found in the read dataframe.\")\n",
    "#         return pd.DataFrame(columns=['book_id', 'title', 'authors'])\n",
    "\n",
    "#     # Books read by the user\n",
    "#     user_books = read_df[(read_df['user_id'] == user_id) & (read_df['is_read'] == 1)]['book_id'].values\n",
    "\n",
    "#     if len(user_books) == 0:\n",
    "#         print(f\"User {user_id} has not read any books.\")\n",
    "#         return pd.DataFrame(columns=['book_id', 'title', 'authors'])\n",
    "\n",
    "#     # Calculate similarity scores for all books\n",
    "#     read_books_indices = [book_df.index[book_df['book_id'] == book_id].tolist()[0] for book_id in user_books if book_id in book_df['book_id'].values]\n",
    "\n",
    "#     if len(read_books_indices) == 0:\n",
    "#         print(f\"No valid book indices found for user {user_id}.\")\n",
    "#         return pd.DataFrame(columns=['book_id', 'title', 'authors'])\n",
    "\n",
    "#     # Calculate average similarity scores for books read by the user\n",
    "#     sim_scores = cosine_sim[read_books_indices].mean(axis=0)\n",
    "\n",
    "#     # Filter out books that the user has already read\n",
    "#     unread_books = book_df[~book_df['book_id'].isin(user_books)].copy()\n",
    "\n",
    "#     if unread_books.empty:\n",
    "#         print(f\"No unread books found for user {user_id}.\")\n",
    "#         return pd.DataFrame(columns=['book_id', 'title', 'authors'])\n",
    "\n",
    "#     # Ensure unread_books indices are within bounds\n",
    "#     valid_unread_books_indices = unread_books.index.values[unread_books.index.values < len(sim_scores)]\n",
    "    \n",
    "#     if len(valid_unread_books_indices) == 0:\n",
    "#         print(f\"No valid unread book indices found for user {user_id}.\")\n",
    "#         return pd.DataFrame(columns=['book_id', 'title', 'authors'])\n",
    "\n",
    "#     unread_books.loc[valid_unread_books_indices, 'similarity'] = [sim_scores[i] for i in valid_unread_books_indices]\n",
    "\n",
    "#     # Get top similar unread books\n",
    "#     top_books = unread_books.sort_values(by='similarity', ascending=False).head(num_recommendations)\n",
    "    \n",
    "#     return top_books['book_id']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "goodreads",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
