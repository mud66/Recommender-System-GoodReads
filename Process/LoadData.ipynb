{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "DIR = '../Data'\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(DIR, 'goodreads_interactions.csv')\n",
    "read = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(DIR, 'book_id_map.csv')\n",
    "book_map = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(DIR, 'goodreads_book_authors.json.gz')\n",
    "authors = pd.read_json(file_path, compression='gzip', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(DIR, 'user_id_map.csv')\n",
    "user_map = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(DIR, 'goodreads_books.json.gz')\n",
    "\n",
    "chunk_size = 1000\n",
    "num_chunks = 1000\n",
    "chunks = pd.read_json(file_path, lines=True, chunksize=chunk_size, compression='gzip')\n",
    "\n",
    "df_list = []\n",
    "\n",
    "for i, chunk in tqdm(enumerate(chunks), total=num_chunks):\n",
    "    for _, row in chunk.iterrows():\n",
    "        df_list.append(row)\n",
    "    if i >= num_chunks:\n",
    "        break\n",
    "\n",
    "books = pd.DataFrame(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(DIR, 'goodreads_book_genres_initial.json.gz')\n",
    "\n",
    "chunks = pd.read_json(file_path, lines=True, chunksize=chunk_size, compression='gzip')\n",
    "\n",
    "df_list = []\n",
    "\n",
    "for i, chunk in tqdm(enumerate(chunks), total=num_chunks):\n",
    "    for _, row in chunk.iterrows():\n",
    "        df_list.append(row)\n",
    "    if i >= num_chunks:\n",
    "        break\n",
    "\n",
    "genres = pd.DataFrame(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(DIR, 'goodreads_reviews_dedup.json.gz')\n",
    "\n",
    "chunks = pd.read_json(file_path, lines=True, chunksize=chunk_size, compression='gzip')\n",
    "\n",
    "df_list = []\n",
    "\n",
    "for i, chunk in tqdm(enumerate(chunks), total=num_chunks):\n",
    "    for _, row in chunk.iterrows():\n",
    "        df_list.append(row)\n",
    "    if i >= num_chunks:\n",
    "        break\n",
    "\n",
    "reviews = pd.DataFrame(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(DIR, 'goodreads_interactions_dedup.json.gz')\n",
    "\n",
    "chunks = pd.read_json(file_path, lines=True, chunksize=chunk_size, compression='gzip')\n",
    "\n",
    "df_list = []\n",
    "\n",
    "for i, chunk in tqdm(enumerate(chunks), total=num_chunks):\n",
    "    for _, row in chunk.iterrows():\n",
    "        df_list.append(row)\n",
    "    if i >= num_chunks:\n",
    "        break\n",
    "\n",
    "interactions = pd.DataFrame(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_empty_rows(df, column_name):\n",
    "   \n",
    "    df_cleaned = df.dropna(subset=[column_name])\n",
    "    return df_cleaned\n",
    "\n",
    "books = drop_empty_rows(books, 'description')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "only keep needed rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions = interactions[['user_id', 'book_id', 'review_id', 'is_read', 'rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = reviews[['user_id', 'book_id', 'review_id', 'rating', 'review_text', 'n_votes', 'n_comments']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = genres.sort_values(by='book_id')\n",
    "books = books.sort_values(by='book_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_genres(genre_dict):\n",
    "    \"\"\"\n",
    "    Filters out genres from a dictionary where the value is None.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    genre_dict (dict): A dictionary where the keys are genre names and the values are their associated values (e.g., popularity, rating, etc.).\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    list: A list of genre names where the values are not None.\n",
    "    \"\"\"\n",
    "    return [genre for genre, value in genre_dict.items() if value is not None]\n",
    "\n",
    "genres['filtered_genres'] = genres['genres'].progress_apply(filter_genres)\n",
    "genres['filtered_genres'] = genres['filtered_genres'].progress_apply(lambda x: ', '.join(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books = pd.merge(books, genres[['book_id', 'filtered_genres']], on='book_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books = books.dropna(subset = ['filtered_genres'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_shelves = ['to-read', 'read', 'currently-reading', 'default', 'owned', 'unread', 'my-library']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_popular_shelves(shelves_list):\n",
    "    \"\"\"\n",
    "    Expands the shelves list based on the count of each shelf and excludes specified shelves.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    shelves_list (list): A list of dictionaries, where each dictionary contains 'name' (shelf name) and 'count' (the number of books in that shelf).\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    str: A space-separated string of shelf names, with each shelf name repeated according to its count, excluding specified shelves.\n",
    "    \"\"\"\n",
    "    expanded_shelves = []\n",
    "    for shelf in shelves_list:\n",
    "        count = int(shelf['count'])\n",
    "        name = shelf['name']\n",
    "        if name not in exclude_shelves:\n",
    "            expanded_shelves.extend([name] * count)\n",
    "    return ' '.join(expanded_shelves)\n",
    "\n",
    "books['expanded_shelves'] = books['popular_shelves'].progress_apply(expand_popular_shelves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions = interactions[interactions['is_read'] != False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions = interactions.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "merge dataframes to get consistent user and book ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions = pd.merge(interactions, user_map, on='user_id', how='left')\n",
    "interactions = pd.merge(interactions, book_map, on='book_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions.drop(columns=['user_id', 'book_id'], inplace=True)\n",
    "interactions.rename(columns={'user_id_csv': 'user_id', 'book_id_csv': 'book_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.merge(reviews, user_map, on='user_id', how='left')\n",
    "reviews = pd.merge(reviews, book_map, on='book_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.drop(columns=['user_id', 'book_id'], inplace=True)\n",
    "reviews.rename(columns={'user_id_csv': 'user_id', 'book_id_csv': 'book_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books = books[['language_code', 'description', 'authors', 'book_id', 'title', 'expanded_shelves', 'average_rating', 'title_without_series', 'filtered_genres']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "map authors and author ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books.loc[:, 'authors'] = books['authors'].progress_apply(lambda x: [author for author in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_name_mapping = authors.set_index('author_id')['name'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books['authors'] = books['authors'].progress_apply(\n",
    "    lambda x: [author_name_mapping[int(author_id['author_id'])] if isinstance(author_id, dict) else author_name_mapping[int(author_id)] for author_id in x]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read.to_pickle('../Pickle/read.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions.to_pickle('../Pickle/interactions.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Pickle/reviews.pkl', 'wb') as file: \n",
    "    pickle.dump(reviews, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "chunk_size = 10000 \n",
    "num_chunks = len(books) // chunk_size + 1\n",
    "progress_bar = tqdm(total=len(books))\n",
    "with open('../Pickle/books.pkl', 'wb') as file:\n",
    "    for i in range(num_chunks):\n",
    "        start_idx = i * chunk_size\n",
    "        end_idx = (i + 1) * chunk_size\n",
    "        chunk = books.iloc[start_idx:end_idx]\n",
    "        for _, row in chunk.iterrows():\n",
    "            progress_bar.update(1)\n",
    "        if i == 0:\n",
    "            pickle.dump(chunk, file)\n",
    "        else:\n",
    "            pickle.dump(chunk, file)\n",
    "progress_bar.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "goodreads",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
